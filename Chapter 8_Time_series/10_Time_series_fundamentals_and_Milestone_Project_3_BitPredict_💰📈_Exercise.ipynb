{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Does scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 & 1)\n",
        "Try doing this for a univariate model (e.g. model_1) and a multivariate model (e.g. model_6) and see if it effects model training or evaluation results"
      ],
      "metadata": {
        "id": "pZtKYMEbp_ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the data and preprocessing it"
      ],
      "metadata": {
        "id": "tNGv4NpSqTGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Bitcoin historical data from GitHub\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
        "\n",
        "# Import with pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",\n",
        "                 parse_dates=[\"Date\"],\n",
        "                 index_col=[\"Date\"]) # parse the date column (tell pandas column 1 is a datetime)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "SwuR7oEcqY4X",
        "outputId": "72464f76-d597-4e1c-a2bb-1c28e041eb90"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-27 18:07:11--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178509 (174K) [text/plain]\n",
            "Saving to: ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv.2’\n",
            "\n",
            "\r          BTC_USD_2   0%[                    ]       0  --.-KB/s               \rBTC_USD_2013-10-01_ 100%[===================>] 174.33K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-08-27 18:07:11 (7.14 MB/s) - ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv.2’ saved [178509/178509]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
              "Date                                                                       \n",
              "2013-10-01      BTC            123.65499       124.30466       124.75166   \n",
              "2013-10-02      BTC            125.45500       123.65499       125.75850   \n",
              "2013-10-03      BTC            108.58483       125.45500       125.66566   \n",
              "2013-10-04      BTC            118.67466       108.58483       118.67500   \n",
              "2013-10-05      BTC            121.33866       118.67466       121.93633   \n",
              "\n",
              "            24h Low (USD)  \n",
              "Date                       \n",
              "2013-10-01      122.56349  \n",
              "2013-10-02      123.63383  \n",
              "2013-10-03       83.32833  \n",
              "2013-10-04      107.05816  \n",
              "2013-10-05      118.00566  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a5a0ada-df6a-46ca-a053-08041e88cc2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>124.30466</td>\n",
              "      <td>124.75166</td>\n",
              "      <td>122.56349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>125.75850</td>\n",
              "      <td>123.63383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>125.66566</td>\n",
              "      <td>83.32833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>118.67500</td>\n",
              "      <td>107.05816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>121.93633</td>\n",
              "      <td>118.00566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a5a0ada-df6a-46ca-a053-08041e88cc2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a5a0ada-df6a-46ca-a053-08041e88cc2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a5a0ada-df6a-46ca-a053-08041e88cc2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48e4c7bf-3f0a-4189-a906-71b6064bda8d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48e4c7bf-3f0a-4189-a906-71b6064bda8d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48e4c7bf-3f0a-4189-a906-71b6064bda8d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only want closing price for each day\n",
        "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\": \"Price\"})\n",
        "bitcoin_prices.head() , bitcoin_prices.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U60Q6GvFqcH7",
        "outputId": "149735f7-0dc6-4dbf-a5af-2dd4ba36047d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                Price\n",
              " Date                 \n",
              " 2013-10-01  123.65499\n",
              " 2013-10-02  125.45500\n",
              " 2013-10-03  108.58483\n",
              " 2013-10-04  118.67466\n",
              " 2013-10-05  121.33866,\n",
              " (2787, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data in array\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "timesteps= bitcoin_prices.index.to_numpy()\n",
        "prices=bitcoin_prices['Price'].to_numpy()\n",
        "\n",
        "#Using minmax scaler to scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()"
      ],
      "metadata": {
        "id": "tcRO3SRFqoUJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to view NumPy arrays as windows\n",
        "\n",
        "def get_labelled_windows(x , horizon):\n",
        "  return x[:, :-horizon] ,x[: , -horizon:]\n",
        "\n",
        "\n",
        "def make_windows_scaled(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size. Also applies the standard scaler\n",
        "  \"\"\"\n",
        "  scaler.fit(np.expand_dims(x , axis =1))\n",
        "  scaled_x = scaler.transform(np.expand_dims(x , axis = 1))\n",
        "  scaled_x = np.squeeze(scaled_x)\n",
        "\n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(scaled_x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  windowed_array = scaled_x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels\n",
        "\n",
        "\n",
        "# Make the splits\n",
        "def make_train_test_splits(windows , labels , test_split = 0.2):\n",
        "  split_size = int(len(windows) * (1 - test_split))\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "\n",
        "  return train_windows ,  test_windows ,train_labels,  test_labels"
      ],
      "metadata": {
        "id": "NmArGUwJrP8w"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_windows(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
        "  \"\"\"\n",
        "\n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  windowed_array = x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels"
      ],
      "metadata": {
        "id": "hz3bOwBk-mSf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 (Horizon = 1 , Window_size = 7)\n",
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "\n",
        "full_windows , full_labels = make_windows_scaled(prices , window_size = WINDOW_SIZE , horizon = HORIZON)\n",
        "full_windows.shape , full_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGWCuiCFrxKy",
        "outputId": "5bfd9259-baab-43cc-e16b-d7548a95e9ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2780, 7), (2780, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at few examples of how price is scaled\n",
        "for i in range(3):\n",
        "  print(f'Window: {full_windows[i]} --> Label {full_labels[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpXbh2Y7sMoo",
        "outputId": "6de053bb-a0d6-4b22-9513-e8b98b52ae9c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window: [0.00023831 0.00026677 0.         0.00015955 0.00020168 0.00019087\n",
            " 0.0002089 ] --> Label [0.00022847]\n",
            "Window: [0.00026677 0.         0.00015955 0.00020168 0.00019087 0.0002089\n",
            " 0.00022847] --> Label [0.00024454]\n",
            "Window: [0.         0.00015955 0.00020168 0.00019087 0.0002089  0.00022847\n",
            " 0.00024454] --> Label [0.00027478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making train and test splits\n",
        "train_windows , test_windows , train_labels , test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "len(train_windows), len(test_windows), len(train_labels), len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSe4Sgd8r0dV",
        "outputId": "d93099ab-475d-4cd4-fac6-6a145cd3ac73"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 556, 2224, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "# Building model 1\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#Construct the model\n",
        "\n",
        "model_1=tf.keras.Sequential([\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dense(HORIZON,activation='linear')\n",
        "])\n",
        "\n",
        "#Compile\n",
        "model_1.compile(\n",
        "      loss='mae',\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=['mae']\n",
        ")\n",
        "\n",
        "#Fit the model\n",
        "model_1.fit(x = train_windows ,\n",
        "            y = train_labels ,\n",
        "            epochs = 100 , batch_size = 128,\n",
        "            validation_data = (test_windows , test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxoheGPtsIz8",
        "outputId": "1825ef8d-a696-44a5-935c-1b5d9159ed1d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0255 - val_mae: 0.0255\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0201 - val_mae: 0.0201\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0221 - val_mae: 0.0221\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0157 - val_mae: 0.0157\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0143 - val_mae: 0.0143\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0178 - val_mae: 0.0178\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0144 - val_mae: 0.0144\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0133 - val_mae: 0.0133\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0147 - val_mae: 0.0147\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0154 - val_mae: 0.0154\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0121 - val_mae: 0.0121\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0133 - val_mae: 0.0133\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0124 - val_mae: 0.0124\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0125 - val_mae: 0.0125\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0123 - val_mae: 0.0123\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0117 - val_mae: 0.0117\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0112 - val_mae: 0.0112\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0116 - val_mae: 0.0116\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0120 - val_mae: 0.0120\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0109 - val_mae: 0.0109\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0124 - val_mae: 0.0124\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0101 - val_mae: 0.0101\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0118 - val_mae: 0.0118\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0111 - val_mae: 0.0111\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0097 - val_mae: 0.0097\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0102 - val_mae: 0.0102\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0098 - val_mae: 0.0098\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0113 - val_mae: 0.0113\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0122 - val_mae: 0.0122\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0110 - val_mae: 0.0110\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0093 - val_mae: 0.0093\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0110 - val_mae: 0.0110\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0139 - val_mae: 0.0139\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0094 - val_mae: 0.0094\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0094 - val_mae: 0.0094\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0117 - val_mae: 0.0117\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0093 - val_mae: 0.0093\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0113 - val_mae: 0.0113\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0110 - val_mae: 0.0110\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0097 - val_mae: 0.0097\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0091 - val_mae: 0.0091\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0094 - val_mae: 0.0094\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0101 - val_mae: 0.0101\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0115 - val_mae: 0.0115\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0098 - val_mae: 0.0098\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0093 - val_mae: 0.0093\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0091 - val_mae: 0.0091\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0095 - val_mae: 0.0095\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0095 - val_mae: 0.0095\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0094 - val_mae: 0.0094\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0130 - val_mae: 0.0130\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0097 - val_mae: 0.0097\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0103 - val_mae: 0.0103\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0091 - val_mae: 0.0091\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0121 - val_mae: 0.0121\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0099 - val_mae: 0.0099\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0097 - val_mae: 0.0097\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0102 - val_mae: 0.0102\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0115 - val_mae: 0.0115\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0104 - val_mae: 0.0104\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0128 - val_mae: 0.0128\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0121 - val_mae: 0.0121\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0093 - val_mae: 0.0093\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0099 - val_mae: 0.0099\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0090 - val_mae: 0.0090\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0110 - val_mae: 0.0110\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0102 - val_mae: 0.0102\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0102 - val_mae: 0.0102\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0095 - val_mae: 0.0095\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0093 - val_mae: 0.0093\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0100 - val_mae: 0.0100\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0110 - val_mae: 0.0110\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0109 - val_mae: 0.0109\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0095 - val_mae: 0.0095\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0104 - val_mae: 0.0104\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0112 - val_mae: 0.0112\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0090 - val_mae: 0.0090\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0096 - val_mae: 0.0096\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0111 - val_mae: 0.0111\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0105 - val_mae: 0.0105\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0092 - val_mae: 0.0092\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0090 - val_mae: 0.0090\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0093 - val_mae: 0.0093\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0090 - val_mae: 0.0090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78a74d492ec0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "model_1.evaluate(test_windows , test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R3xR7FytG2W",
        "outputId": "172e236f-1a8c-4692-c9d7-38aa79adeb66"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0089936014264822, 0.0089936014264822]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "model_1_preds = tf.squeeze(model_1.predict(test_windows))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzaPInAbtVx9",
        "outputId": "b964ddbf-452c-4157-b0d2-088d7dcef82f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now doing the same for the Multivariate data especially for the Model 6"
      ],
      "metadata": {
        "id": "ImcAObI7tZjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block reward values\n",
        "block_reward_1 = 50 # 3 January 2009\n",
        "block_reward_2 = 25 # 28 November 2012\n",
        "block_reward_3 = 12.5 # 9 July 2016\n",
        "block_reward_4 = 6.25 # 11 May 2020\n",
        "\n",
        "# Block reward dates (datetime form of the above date stamps)\n",
        "block_reward_2_datetime = np.datetime64(\"2012-11-28\")\n",
        "block_reward_3_datetime = np.datetime64(\"2016-07-09\")\n",
        "block_reward_4_datetime = np.datetime64(\"2020-05-11\")\n",
        "\n",
        "# Get date indexes for when to add in different block dates\n",
        "block_reward_2_days = (block_reward_3_datetime - bitcoin_prices.index[0]).days\n",
        "block_reward_3_days = (block_reward_4_datetime - bitcoin_prices.index[0]).days\n",
        "block_reward_2_days, block_reward_3_days\n",
        "\n",
        "# Add block_reward column\n",
        "bitcoin_prices_block = bitcoin_prices.copy()\n",
        "bitcoin_prices_block[\"block_reward\"] = None\n",
        "\n",
        "# Set values of block_reward column (it's the last column hence -1 indexing on iloc)\n",
        "bitcoin_prices_block.iloc[:block_reward_2_days, -1] = block_reward_2\n",
        "bitcoin_prices_block.iloc[block_reward_2_days:block_reward_3_days, -1] = block_reward_3\n",
        "bitcoin_prices_block.iloc[block_reward_3_days:, -1] = block_reward_4\n",
        "bitcoin_prices_block.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "i-UYbawctgcT",
        "outputId": "22ce0d43-55ba-4ef7-d3b1-46c5844245b8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Price block_reward\n",
              "Date                              \n",
              "2013-10-01  123.65499           25\n",
              "2013-10-02  125.45500           25\n",
              "2013-10-03  108.58483           25\n",
              "2013-10-04  118.67466           25\n",
              "2013-10-05  121.33866           25"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d87bc8f8-c2b6-48b8-bb2b-4b7f49e1db70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>block_reward</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>123.65499</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>125.45500</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>108.58483</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>118.67466</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>121.33866</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d87bc8f8-c2b6-48b8-bb2b-4b7f49e1db70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d87bc8f8-c2b6-48b8-bb2b-4b7f49e1db70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d87bc8f8-c2b6-48b8-bb2b-4b7f49e1db70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea25b821-7823-42bb-8d2f-f7300c28fef0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea25b821-7823-42bb-8d2f-f7300c28fef0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea25b821-7823-42bb-8d2f-f7300c28fef0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make a copy of the Bitcoin historical data with block reward feature\n",
        "bitcoin_prices_windowed = bitcoin_prices_block.copy()\n",
        "\n",
        "# Add windowed columns\n",
        "for i in range(WINDOW_SIZE):\n",
        "  bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
        "bitcoin_prices_windowed.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "zV0zrNd8xo-k",
        "outputId": "f29122c4-3aa5-4b77-f95b-ea56f6795312"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Price block_reward    Price+1    Price+2    Price+3  \\\n",
              "Date                                                                  \n",
              "2013-10-01  123.65499           25        NaN        NaN        NaN   \n",
              "2013-10-02  125.45500           25  123.65499        NaN        NaN   \n",
              "2013-10-03  108.58483           25  125.45500  123.65499        NaN   \n",
              "2013-10-04  118.67466           25  108.58483  125.45500  123.65499   \n",
              "2013-10-05  121.33866           25  118.67466  108.58483  125.45500   \n",
              "2013-10-06  120.65533           25  121.33866  118.67466  108.58483   \n",
              "2013-10-07  121.79500           25  120.65533  121.33866  118.67466   \n",
              "2013-10-08  123.03300           25  121.79500  120.65533  121.33866   \n",
              "2013-10-09  124.04900           25  123.03300  121.79500  120.65533   \n",
              "2013-10-10  125.96116           25  124.04900  123.03300  121.79500   \n",
              "\n",
              "              Price+4    Price+5    Price+6    Price+7  \n",
              "Date                                                    \n",
              "2013-10-01        NaN        NaN        NaN        NaN  \n",
              "2013-10-02        NaN        NaN        NaN        NaN  \n",
              "2013-10-03        NaN        NaN        NaN        NaN  \n",
              "2013-10-04        NaN        NaN        NaN        NaN  \n",
              "2013-10-05  123.65499        NaN        NaN        NaN  \n",
              "2013-10-06  125.45500  123.65499        NaN        NaN  \n",
              "2013-10-07  108.58483  125.45500  123.65499        NaN  \n",
              "2013-10-08  118.67466  108.58483  125.45500  123.65499  \n",
              "2013-10-09  121.33866  118.67466  108.58483  125.45500  \n",
              "2013-10-10  120.65533  121.33866  118.67466  108.58483  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99ef2faa-29bf-4ef7-be3a-ceba09fdcad1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>block_reward</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>123.65499</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>125.45500</td>\n",
              "      <td>25</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>108.58483</td>\n",
              "      <td>25</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>118.67466</td>\n",
              "      <td>25</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>121.33866</td>\n",
              "      <td>25</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-06</th>\n",
              "      <td>120.65533</td>\n",
              "      <td>25</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>121.79500</td>\n",
              "      <td>25</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>123.03300</td>\n",
              "      <td>25</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>124.04900</td>\n",
              "      <td>25</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>125.96116</td>\n",
              "      <td>25</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99ef2faa-29bf-4ef7-be3a-ceba09fdcad1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99ef2faa-29bf-4ef7-be3a-ceba09fdcad1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99ef2faa-29bf-4ef7-be3a-ceba09fdcad1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b45e6f9-9fb8-4c32-9ec7-71538ac1e707\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b45e6f9-9fb8-4c32-9ec7-71538ac1e707')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b45e6f9-9fb8-4c32-9ec7-71538ac1e707 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create X & y, remove the NaN's and convert to float32 to prevent TensorFlow errors\n",
        "X = bitcoin_prices_windowed.dropna().drop(\"Price\", axis=1).astype(np.float32)\n",
        "y = bitcoin_prices_windowed.dropna()[\"Price\"].astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "wy0f5g2k39-T",
        "outputId": "c53e4dab-bf2d-4a83-f573-43a530684d37"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            block_reward     Price+1     Price+2     Price+3     Price+4  \\\n",
              "Date                                                                       \n",
              "2013-10-08          25.0  121.794998  120.655327  121.338661  118.674660   \n",
              "2013-10-09          25.0  123.032997  121.794998  120.655327  121.338661   \n",
              "2013-10-10          25.0  124.049004  123.032997  121.794998  120.655327   \n",
              "2013-10-11          25.0  125.961159  124.049004  123.032997  121.794998   \n",
              "2013-10-12          25.0  125.279663  125.961159  124.049004  123.032997   \n",
              "\n",
              "               Price+5     Price+6     Price+7  \n",
              "Date                                            \n",
              "2013-10-08  108.584831  125.455002  123.654991  \n",
              "2013-10-09  118.674660  108.584831  125.455002  \n",
              "2013-10-10  121.338661  118.674660  108.584831  \n",
              "2013-10-11  120.655327  121.338661  118.674660  \n",
              "2013-10-12  121.794998  120.655327  121.338661  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09033791-fbf4-480b-95f0-ea7e68543d7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>block_reward</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>25.0</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>123.654991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>25.0</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>25.0</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-11</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-12</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.279663</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09033791-fbf4-480b-95f0-ea7e68543d7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09033791-fbf4-480b-95f0-ea7e68543d7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09033791-fbf4-480b-95f0-ea7e68543d7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16dfaecf-c42d-4fdc-8e7d-605f0a856a97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16dfaecf-c42d-4fdc-8e7d-605f0a856a97')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16dfaecf-c42d-4fdc-8e7d-605f0a856a97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the X data\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y_scaled = scaler.fit_transform(np.expand_dims(y , axis = 1))\n",
        "y_scaled = np.squeeze(y_scaled)"
      ],
      "metadata": {
        "id": "apEkQeM14FGa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make train and test set splits of the scaled data\n",
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvFtoVCQ4KSh",
        "outputId": "cb5e4102-4544-4353-b6ec-d9982e92679d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2224, 556, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Building a Multivariate time series model and fitting it\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "  layers.Dense(128 , activation= 'relu'),\n",
        "  layers.Dense(HORIZON)\n",
        "])\n",
        "\n",
        "model_6.compile(loss = 'mae' ,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "model_6.fit(X_train , y_train ,\n",
        "          epochs = 100 ,\n",
        "           batch_size = 128,\n",
        "          validation_data = (X_test , y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3RbaVIk4PJ2",
        "outputId": "ddd8a141-71f1-4c47-f532-1b375ebe43ed"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 2s 22ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0333 - val_mae: 0.0333\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0247 - val_mae: 0.0247\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0239 - val_mae: 0.0239\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0313 - val_mae: 0.0313\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0268 - val_mae: 0.0268\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0313 - val_mae: 0.0313\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0278 - val_mae: 0.0278\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0295 - val_mae: 0.0295\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0297 - val_mae: 0.0297\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0276 - val_mae: 0.0276\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0267 - val_mae: 0.0267\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0330 - val_mae: 0.0330\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0313 - val_mae: 0.0313\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0305 - val_mae: 0.0305\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0376 - val_mae: 0.0376\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0340 - val_mae: 0.0340\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0310 - val_mae: 0.0310\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0348 - val_mae: 0.0348\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0320 - val_mae: 0.0320\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0278 - val_mae: 0.0278\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0300 - val_mae: 0.0300\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0311 - val_mae: 0.0311\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0316 - val_mae: 0.0316\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0322 - val_mae: 0.0322\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0302 - val_mae: 0.0302\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0301 - val_mae: 0.0301\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0312 - val_mae: 0.0312\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0331 - val_mae: 0.0331\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0308 - val_mae: 0.0308\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0339 - val_mae: 0.0339\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0347 - val_mae: 0.0347\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0333 - val_mae: 0.0333\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0328 - val_mae: 0.0328\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0322 - val_mae: 0.0322\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0316 - val_mae: 0.0316\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0335 - val_mae: 0.0335\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0330 - val_mae: 0.0330\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0318 - val_mae: 0.0318\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0320 - val_mae: 0.0320\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0303 - val_mae: 0.0303\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0309 - val_mae: 0.0309\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0318 - val_mae: 0.0318\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0315 - val_mae: 0.0315\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0290 - val_mae: 0.0290\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0305 - val_mae: 0.0305\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0342 - val_mae: 0.0342\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0308 - val_mae: 0.0308\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0304 - val_mae: 0.0304\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0306 - val_mae: 0.0306\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0310 - val_mae: 0.0310\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0316 - val_mae: 0.0316\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0304 - val_mae: 0.0304\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0304 - val_mae: 0.0304\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0367 - val_mae: 0.0367\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0322 - val_mae: 0.0322\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0302 - val_mae: 0.0302\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0382 - val_mae: 0.0382\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0275 - val_mae: 0.0275\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0338 - val_mae: 0.0338\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0336 - val_mae: 0.0336\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0444 - val_mae: 0.0444\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0285 - val_mae: 0.0285\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0331 - val_mae: 0.0331\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0372 - val_mae: 0.0372\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0315 - val_mae: 0.0315\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0330 - val_mae: 0.0330\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0341 - val_mae: 0.0341\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0326 - val_mae: 0.0326\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0329 - val_mae: 0.0329\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0322 - val_mae: 0.0322\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0332 - val_mae: 0.0332\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0309 - val_mae: 0.0309\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0319 - val_mae: 0.0319\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0336 - val_mae: 0.0336\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0306 - val_mae: 0.0306\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0311 - val_mae: 0.0311\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0328 - val_mae: 0.0328\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0312 - val_mae: 0.0312\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0297 - val_mae: 0.0297\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0027 - val_loss: 0.0331 - val_mae: 0.0331\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0317 - val_mae: 0.0317\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0316 - val_mae: 0.0316\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0320 - val_mae: 0.0320\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0306 - val_mae: 0.0306\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0305 - val_mae: 0.0305\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0324 - val_mae: 0.0324\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0303 - val_mae: 0.0303\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0308 - val_mae: 0.0308\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0302 - val_mae: 0.0302\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0337 - val_mae: 0.0337\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0307 - val_mae: 0.0307\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0290 - val_mae: 0.0290\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0310 - val_mae: 0.0310\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0308 - val_mae: 0.0308\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0322 - val_mae: 0.0322\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0315 - val_mae: 0.0315\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0314 - val_mae: 0.0314\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0308 - val_mae: 0.0308\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0273 - val_mae: 0.0273\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0308 - val_mae: 0.0308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78a74d6b49d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model 6\n",
        "model_6.evaluate(X_test , y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQcOZmtF4TCm",
        "outputId": "fef560de-38ad-4b9f-fcf4-38f126842825"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0308 - mae: 0.0308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.030826279893517494, 0.030826279893517494]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. For most of our models we used WINDOW_SIZE=7, but is there a better window size?\n",
        "\n",
        "* Setup a series of experiments to find whether or not there’s a better window size.\n",
        "* For example, you might train 10 different models with HORIZON=1 but with window sizes ranging from 2-12."
      ],
      "metadata": {
        "id": "F1FTsa044Zj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing a evaluation function based on the preds and targets\n",
        "def evaluate_preds(y_true , y_pred):\n",
        "\n",
        "  # Casting the values to float32\n",
        "  y_true = tf.cast(y_true , tf.float32)\n",
        "  y_pred = tf.cast(y_pred , tf.float32)\n",
        "\n",
        "\n",
        "  # Calculate the metrics\n",
        "  mae = tf.keras.metrics.mean_absolute_error(y_true , y_pred)\n",
        "  mse = tf.keras.metrics.mean_squared_error(y_true , y_pred)\n",
        "  rmse = tf.sqrt(mse)\n",
        "  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true , y_pred)\n",
        "\n",
        "  # For longer horizons\n",
        "  if mae.ndim > 0:\n",
        "    mae = tf.reduce_sum(mae)\n",
        "    mse = tf.reduce_sum(mse)\n",
        "    rmse = tf.reduce_sum(rmse)\n",
        "    mape = tf.reduce_sum(mape)\n",
        "\n",
        "  return {'mae' : mae.numpy() ,\n",
        "          'mse': mse.numpy() ,\n",
        "          'rmse': rmse.numpy() ,\n",
        "          'mape': mape.numpy() }\n",
        ""
      ],
      "metadata": {
        "id": "h8Y014097CCb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing a for loop to iterate over the Window size and build 10 different models\n",
        "\n",
        "# 10 Different models with window size ranging from (2 - 12) and store the results\n",
        "model_results_list = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "for size in tqdm(range(2,12)):\n",
        "  HORIZON = 1\n",
        "  WINDOW_SIZE = size\n",
        "\n",
        "  # Making window and labels\n",
        "  full_windows , full_labels = make_windows_scaled(prices, window_size= WINDOW_SIZE , horizon= HORIZON)\n",
        "\n",
        "\n",
        "  # Splitting the data in train and test\n",
        "  train_windows ,  test_windows ,train_labels,  test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "\n",
        "  # Building a simple dense model\n",
        "  input = layers.Input(shape = (WINDOW_SIZE ,) , name = 'Input_layer')\n",
        "  x = layers.Dense(128 , activation= 'relu')(input)\n",
        "  output = layers.Dense(HORIZON , activation= 'linear')(x)\n",
        "\n",
        "  # Packing into a model\n",
        "  model = tf.keras.Model(input , output , name = f'model_windowed_{size}')\n",
        "  model_window_size=f'model_windowed_{size}'\n",
        "  # Compiling and fitting the model\n",
        "  model.compile(loss = 'mae' , optimizer = 'adam' , metrics = 'mae')\n",
        "\n",
        "  model.fit(train_windows , train_labels ,\n",
        "            epochs = 100 , verbose = 0 ,\n",
        "            batch_size = 128 ,\n",
        "            validation_data = (test_windows , test_labels))\n",
        "\n",
        "\n",
        "  # Making predictions\n",
        "  preds_ = model.predict(test_windows)\n",
        "  y_preds = tf.squeeze(preds_)\n",
        "\n",
        "  results = evaluate_preds(tf.squeeze(test_labels) , y_preds)\n",
        "  model_results_list.append([model_window_size,results])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVEBvQOY89HW",
        "outputId": "a1ce342e-ab08-48f4-d2f9-8ffa94ce2374"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:09<01:27,  9.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:19<01:17,  9.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:30<01:11, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:39<00:57,  9.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:48<00:47,  9.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:57<00:38,  9.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:07<00:28,  9.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:18<00:19,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [01:29<00:10, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:40<00:00, 10.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below are the 10 different models result\n",
        "model_results_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNR5dgv1_U0y",
        "outputId": "908b0a6f-c997-4c52-c881-c125788ebf3d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['model_windowed_2',\n",
              "  {'mae': 0.039380837,\n",
              "   'mse': 0.0059549557,\n",
              "   'rmse': 0.07716836,\n",
              "   'mape': 6.468268}],\n",
              " ['model_windowed_3',\n",
              "  {'mae': 0.025282605,\n",
              "   'mse': 0.0023363302,\n",
              "   'rmse': 0.0483356,\n",
              "   'mape': 4.656902}],\n",
              " ['model_windowed_4',\n",
              "  {'mae': 0.017092451,\n",
              "   'mse': 0.0010364477,\n",
              "   'rmse': 0.032193907,\n",
              "   'mape': 3.6509101}],\n",
              " ['model_windowed_5',\n",
              "  {'mae': 0.010831884,\n",
              "   'mse': 0.00040410133,\n",
              "   'rmse': 0.020102272,\n",
              "   'mape': 2.830551}],\n",
              " ['model_windowed_6',\n",
              "  {'mae': 0.015103316,\n",
              "   'mse': 0.00083604717,\n",
              "   'rmse': 0.02891448,\n",
              "   'mape': 3.3253245}],\n",
              " ['model_windowed_7',\n",
              "  {'mae': 0.010114647,\n",
              "   'mse': 0.00035978024,\n",
              "   'rmse': 0.018967874,\n",
              "   'mape': 2.7291884}],\n",
              " ['model_windowed_8',\n",
              "  {'mae': 0.014222335,\n",
              "   'mse': 0.0006974287,\n",
              "   'rmse': 0.026408875,\n",
              "   'mape': 3.347475}],\n",
              " ['model_windowed_9',\n",
              "  {'mae': 0.013515882,\n",
              "   'mse': 0.0005344258,\n",
              "   'rmse': 0.02311765,\n",
              "   'mape': 3.7472074}],\n",
              " ['model_windowed_10',\n",
              "  {'mae': 0.01022411,\n",
              "   'mse': 0.0003548235,\n",
              "   'rmse': 0.018836759,\n",
              "   'mape': 2.8311691}],\n",
              " ['model_windowed_11',\n",
              "  {'mae': 0.01016229,\n",
              "   'mse': 0.00035139627,\n",
              "   'rmse': 0.018745566,\n",
              "   'mape': 2.7731693}]]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create a windowed dataset just like the ones we used for model_1 using tf.keras.preprocessing.timeseries_dataset_from_array() and retrain model_1 using the recreated dataset"
      ],
      "metadata": {
        "id": "PrOsQC-b_baw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 7\n",
        "HORIZON = 1\n",
        ""
      ],
      "metadata": {
        "id": "k1KsoJAmBgUR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the splits\n",
        "def make_train_test_splits(windows , labels , test_split = 0.2):\n",
        "  split_size = int(len(windows) * (1 - test_split))\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "\n",
        "  return train_windows ,  test_windows ,train_labels,  test_labels"
      ],
      "metadata": {
        "id": "dIFC2NTgMAm7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data = prices , targets = prices , sequence_length = WINDOW_SIZE , sequence_stride = HORIZON,\n",
        "    batch_size = 128\n",
        ")"
      ],
      "metadata": {
        "id": "UnHAJqhYME24"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size , test_size = int(0.8 * len(ds)) ,int(0.2 * len(ds))"
      ],
      "metadata": {
        "id": "UJ7V-ecuMY0k"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ds.take(train_size)\n",
        "test_ds = ds.skip(train_size).take(test_size)"
      ],
      "metadata": {
        "id": "4sbXvHDGMPOH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x , y in train_ds.take(1):\n",
        "  print(x[:2] , y[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEllZA3PMWFY",
        "outputId": "070a8f12-6c79-41e9-ff49-d8777260ac4b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[123.65499 125.455   108.58483 118.67466 121.33866 120.65533 121.795\n",
            "  123.033   124.049   125.96116 125.27966]\n",
            " [125.455   108.58483 118.67466 121.33866 120.65533 121.795   123.033\n",
            "  124.049   125.96116 125.27966 125.9275 ]], shape=(2, 11), dtype=float64) tf.Tensor([123.65499 125.455  ], shape=(2,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Model 1 with the updated data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Building a simple dense model\n",
        "input = layers.Input(shape = (WINDOW_SIZE ,) , name = 'Input_layer' , dtype = tf.float32)\n",
        "x = layers.Dense(128 , activation= 'relu')(input)\n",
        "output = layers.Dense(HORIZON , activation= 'linear')(x)\n",
        "\n",
        "# Packing into a model\n",
        "model = tf.keras.Model(input , output)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss = 'mae' ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_ds ,\n",
        "          epochs = 100 , verbose = 1 ,\n",
        "            validation_data = test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OwOSDdMMfiG",
        "outputId": "c06ead42-c1ea-4250-ae55-c1e341691fc3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 3s 78ms/step - loss: 409.6984 - mae: 409.6984 - val_loss: 741.1929 - val_mae: 741.1929\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 429.6542 - mae: 429.6542 - val_loss: 2013.0236 - val_mae: 2013.0236\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 387.3918 - mae: 387.3918 - val_loss: 1063.3564 - val_mae: 1063.3564\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 522.0448 - mae: 522.0448 - val_loss: 1124.7953 - val_mae: 1124.7953\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 915.7665 - mae: 915.7665 - val_loss: 1498.8575 - val_mae: 1498.8575\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 849.1249 - mae: 849.1249 - val_loss: 1355.8940 - val_mae: 1355.8940\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 610.5486 - mae: 610.5486 - val_loss: 995.9439 - val_mae: 995.9439\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 725.4698 - mae: 725.4698 - val_loss: 1096.5327 - val_mae: 1096.5327\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 604.2969 - mae: 604.2969 - val_loss: 1068.8812 - val_mae: 1068.8812\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 663.5388 - mae: 663.5388 - val_loss: 1008.6923 - val_mae: 1008.6923\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 574.6824 - mae: 574.6824 - val_loss: 1058.4115 - val_mae: 1058.4115\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 610.7297 - mae: 610.7297 - val_loss: 924.6243 - val_mae: 924.6243\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 552.9179 - mae: 552.9179 - val_loss: 1054.5056 - val_mae: 1054.5056\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 568.4919 - mae: 568.4919 - val_loss: 876.5928 - val_mae: 876.5928\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 521.5133 - mae: 521.5133 - val_loss: 989.1975 - val_mae: 989.1975\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 554.2260 - mae: 554.2260 - val_loss: 867.6304 - val_mae: 867.6304\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 505.5107 - mae: 505.5107 - val_loss: 981.9438 - val_mae: 981.9438\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 528.0242 - mae: 528.0242 - val_loss: 830.6907 - val_mae: 830.6907\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 494.5650 - mae: 494.5650 - val_loss: 968.5002 - val_mae: 968.5002\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 518.4946 - mae: 518.4946 - val_loss: 833.6837 - val_mae: 833.6837\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 1s 34ms/step - loss: 475.0392 - mae: 475.0392 - val_loss: 943.0537 - val_mae: 943.0537\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 500.7078 - mae: 500.7078 - val_loss: 811.4601 - val_mae: 811.4601\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 458.9776 - mae: 458.9776 - val_loss: 915.8369 - val_mae: 915.8369\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 486.8505 - mae: 486.8505 - val_loss: 796.5021 - val_mae: 796.5021\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 445.2312 - mae: 445.2312 - val_loss: 912.3311 - val_mae: 912.3311\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 460.1037 - mae: 460.1037 - val_loss: 764.0476 - val_mae: 764.0476\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 428.2152 - mae: 428.2152 - val_loss: 877.2631 - val_mae: 877.2631\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 450.8635 - mae: 450.8635 - val_loss: 752.3796 - val_mae: 752.3796\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 416.5938 - mae: 416.5938 - val_loss: 862.6371 - val_mae: 862.6371\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 432.2600 - mae: 432.2600 - val_loss: 727.2870 - val_mae: 727.2870\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 1s 35ms/step - loss: 409.8489 - mae: 409.8489 - val_loss: 850.0971 - val_mae: 850.0971\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 426.2644 - mae: 426.2644 - val_loss: 720.0453 - val_mae: 720.0453\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 401.2242 - mae: 401.2242 - val_loss: 833.2667 - val_mae: 833.2667\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 422.7356 - mae: 422.7356 - val_loss: 717.5586 - val_mae: 717.5586\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 395.2948 - mae: 395.2948 - val_loss: 829.1752 - val_mae: 829.1752\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 414.7817 - mae: 414.7817 - val_loss: 713.8270 - val_mae: 713.8270\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 384.6100 - mae: 384.6100 - val_loss: 815.2358 - val_mae: 815.2358\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 405.4149 - mae: 405.4149 - val_loss: 700.7797 - val_mae: 700.7797\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 380.1398 - mae: 380.1398 - val_loss: 809.7091 - val_mae: 809.7091\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 398.9084 - mae: 398.9084 - val_loss: 693.4413 - val_mae: 693.4413\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 374.6756 - mae: 374.6756 - val_loss: 807.4198 - val_mae: 807.4198\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 387.6284 - mae: 387.6284 - val_loss: 677.9836 - val_mae: 677.9836\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 372.7950 - mae: 372.7950 - val_loss: 808.3199 - val_mae: 808.3199\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 379.1600 - mae: 379.1600 - val_loss: 666.7313 - val_mae: 666.7313\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 363.9984 - mae: 363.9984 - val_loss: 791.2211 - val_mae: 791.2211\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 367.0305 - mae: 367.0305 - val_loss: 650.3575 - val_mae: 650.3575\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 340.1418 - mae: 340.1418 - val_loss: 733.5802 - val_mae: 733.5802\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 353.4908 - mae: 353.4908 - val_loss: 624.0871 - val_mae: 624.0871\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 346.3247 - mae: 346.3247 - val_loss: 752.4038 - val_mae: 752.4038\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 351.6549 - mae: 351.6549 - val_loss: 632.4073 - val_mae: 632.4073\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 331.2530 - mae: 331.2530 - val_loss: 718.8041 - val_mae: 718.8041\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 344.4523 - mae: 344.4523 - val_loss: 617.2615 - val_mae: 617.2615\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 334.3287 - mae: 334.3287 - val_loss: 728.1031 - val_mae: 728.1031\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 343.4482 - mae: 343.4482 - val_loss: 623.9575 - val_mae: 623.9575\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 322.1975 - mae: 322.1975 - val_loss: 703.7791 - val_mae: 703.7791\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 336.7843 - mae: 336.7843 - val_loss: 612.3179 - val_mae: 612.3179\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 324.3098 - mae: 324.3098 - val_loss: 712.5680 - val_mae: 712.5680\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 332.6705 - mae: 332.6705 - val_loss: 608.8500 - val_mae: 608.8500\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 319.7209 - mae: 319.7209 - val_loss: 703.6494 - val_mae: 703.6494\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 329.0398 - mae: 329.0398 - val_loss: 604.5300 - val_mae: 604.5300\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 317.4240 - mae: 317.4240 - val_loss: 704.4936 - val_mae: 704.4936\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 323.5644 - mae: 323.5644 - val_loss: 599.9113 - val_mae: 599.9113\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 312.0590 - mae: 312.0590 - val_loss: 696.0941 - val_mae: 696.0941\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 319.5749 - mae: 319.5749 - val_loss: 595.0084 - val_mae: 595.0084\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 309.1974 - mae: 309.1974 - val_loss: 692.7789 - val_mae: 692.7789\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 314.0157 - mae: 314.0157 - val_loss: 589.2207 - val_mae: 589.2207\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 306.2233 - mae: 306.2233 - val_loss: 689.3655 - val_mae: 689.3655\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 313.8972 - mae: 313.8972 - val_loss: 594.5659 - val_mae: 594.5659\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 295.9143 - mae: 295.9143 - val_loss: 663.0662 - val_mae: 663.0662\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 302.3242 - mae: 302.3242 - val_loss: 570.3169 - val_mae: 570.3169\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 301.1883 - mae: 301.1883 - val_loss: 686.7833 - val_mae: 686.7833\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 306.9226 - mae: 306.9226 - val_loss: 595.7330 - val_mae: 595.7330\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 286.6248 - mae: 286.6248 - val_loss: 672.2306 - val_mae: 672.2306\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 291.8058 - mae: 291.8058 - val_loss: 577.5885 - val_mae: 577.5885\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 282.6295 - mae: 282.6295 - val_loss: 664.0117 - val_mae: 664.0117\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 286.9534 - mae: 286.9534 - val_loss: 570.4851 - val_mae: 570.4851\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 276.4599 - mae: 276.4599 - val_loss: 647.6694 - val_mae: 647.6694\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 283.5957 - mae: 283.5957 - val_loss: 563.6765 - val_mae: 563.6765\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 275.5018 - mae: 275.5018 - val_loss: 640.8573 - val_mae: 640.8573\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 284.5471 - mae: 284.5471 - val_loss: 558.2112 - val_mae: 558.2112\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 277.1429 - mae: 277.1429 - val_loss: 627.5749 - val_mae: 627.5749\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 284.9162 - mae: 284.9162 - val_loss: 548.2930 - val_mae: 548.2930\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 284.5752 - mae: 284.5752 - val_loss: 636.9088 - val_mae: 636.9088\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 296.9433 - mae: 296.9433 - val_loss: 568.7267 - val_mae: 568.7267\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 275.5933 - mae: 275.5933 - val_loss: 631.3268 - val_mae: 631.3268\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 282.3832 - mae: 282.3832 - val_loss: 547.5823 - val_mae: 547.5823\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 277.9066 - mae: 277.9066 - val_loss: 633.8690 - val_mae: 633.8690\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 286.2597 - mae: 286.2597 - val_loss: 558.3075 - val_mae: 558.3075\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 272.2486 - mae: 272.2486 - val_loss: 635.4271 - val_mae: 635.4271\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 275.8880 - mae: 275.8880 - val_loss: 547.1717 - val_mae: 547.1717\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 269.6904 - mae: 269.6904 - val_loss: 625.8571 - val_mae: 625.8571\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 275.8323 - mae: 275.8323 - val_loss: 544.5206 - val_mae: 544.5206\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 268.8402 - mae: 268.8402 - val_loss: 619.4219 - val_mae: 619.4219\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 275.3796 - mae: 275.3796 - val_loss: 540.0840 - val_mae: 540.0840\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 268.0817 - mae: 268.0817 - val_loss: 610.9749 - val_mae: 610.9749\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 274.1733 - mae: 274.1733 - val_loss: 530.2239 - val_mae: 530.2239\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 268.1705 - mae: 268.1705 - val_loss: 607.5316 - val_mae: 607.5316\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 277.1880 - mae: 277.1880 - val_loss: 537.3975 - val_mae: 537.3975\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 264.1039 - mae: 264.1039 - val_loss: 612.2791 - val_mae: 612.2791\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 267.6164 - mae: 267.6164 - val_loss: 528.1802 - val_mae: 528.1802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78a74d3a79a0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the test set\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HyYSVcXMldG",
        "outputId": "40126da8-b8c5-4ebf-b98f-e41d22872756"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 17ms/step - loss: 528.1802 - mae: 528.1802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[528.18017578125, 528.18017578125]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **For our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.\n",
        "Are there any other features you think you could add?**  \n",
        "If so, try it out, how do these affect the model?"
      ],
      "metadata": {
        "id": "lHwYyejLMpcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "xOln3Z2CNv1B",
        "outputId": "9d58d1ec-1223-4301-ed39-596b84ec78e7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
              "Date                                                                       \n",
              "2013-10-01      BTC           123.654990      124.304660      124.751660   \n",
              "2013-10-02      BTC           125.455000      123.654990      125.758500   \n",
              "2013-10-03      BTC           108.584830      125.455000      125.665660   \n",
              "2013-10-04      BTC           118.674660      108.584830      118.675000   \n",
              "2013-10-05      BTC           121.338660      118.674660      121.936330   \n",
              "...             ...                  ...             ...             ...   \n",
              "2021-05-14      BTC         49764.132082    49596.778891    51448.798576   \n",
              "2021-05-15      BTC         50032.693137    49717.354353    51578.312545   \n",
              "2021-05-16      BTC         47885.625255    49926.035067    50690.802950   \n",
              "2021-05-17      BTC         45604.615754    46805.537852    49670.414174   \n",
              "2021-05-18      BTC         43144.471291    46439.336570    46622.853437   \n",
              "\n",
              "            24h Low (USD)  \n",
              "Date                       \n",
              "2013-10-01     122.563490  \n",
              "2013-10-02     123.633830  \n",
              "2013-10-03      83.328330  \n",
              "2013-10-04     107.058160  \n",
              "2013-10-05     118.005660  \n",
              "...                   ...  \n",
              "2021-05-14   46294.720180  \n",
              "2021-05-15   48944.346536  \n",
              "2021-05-16   47005.102292  \n",
              "2021-05-17   43868.638969  \n",
              "2021-05-18   42102.346430  \n",
              "\n",
              "[2787 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dbacc13-60bb-4c84-bb56-8b59f3235571\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.654990</td>\n",
              "      <td>124.304660</td>\n",
              "      <td>124.751660</td>\n",
              "      <td>122.563490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.455000</td>\n",
              "      <td>123.654990</td>\n",
              "      <td>125.758500</td>\n",
              "      <td>123.633830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.584830</td>\n",
              "      <td>125.455000</td>\n",
              "      <td>125.665660</td>\n",
              "      <td>83.328330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584830</td>\n",
              "      <td>118.675000</td>\n",
              "      <td>107.058160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.338660</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>121.936330</td>\n",
              "      <td>118.005660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-14</th>\n",
              "      <td>BTC</td>\n",
              "      <td>49764.132082</td>\n",
              "      <td>49596.778891</td>\n",
              "      <td>51448.798576</td>\n",
              "      <td>46294.720180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-15</th>\n",
              "      <td>BTC</td>\n",
              "      <td>50032.693137</td>\n",
              "      <td>49717.354353</td>\n",
              "      <td>51578.312545</td>\n",
              "      <td>48944.346536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-16</th>\n",
              "      <td>BTC</td>\n",
              "      <td>47885.625255</td>\n",
              "      <td>49926.035067</td>\n",
              "      <td>50690.802950</td>\n",
              "      <td>47005.102292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-17</th>\n",
              "      <td>BTC</td>\n",
              "      <td>45604.615754</td>\n",
              "      <td>46805.537852</td>\n",
              "      <td>49670.414174</td>\n",
              "      <td>43868.638969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-18</th>\n",
              "      <td>BTC</td>\n",
              "      <td>43144.471291</td>\n",
              "      <td>46439.336570</td>\n",
              "      <td>46622.853437</td>\n",
              "      <td>42102.346430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2787 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dbacc13-60bb-4c84-bb56-8b59f3235571')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dbacc13-60bb-4c84-bb56-8b59f3235571 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dbacc13-60bb-4c84-bb56-8b59f3235571');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4428a8e7-0756-48e5-8cf0-2436f23d9da8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4428a8e7-0756-48e5-8cf0-2436f23d9da8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4428a8e7-0756-48e5-8cf0-2436f23d9da8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n"
      ],
      "metadata": {
        "id": "5f0ukT7wNyJp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a day of week feature\n",
        "df['day_of_week'] = df.index.dayofweek\n",
        "df.head(10)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "ZJ8o4f0KOUaH",
        "outputId": "e9f4e8e5-3acb-481f-bd49-36ceaa7402c0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
              "Date                                                                       \n",
              "2013-10-01      BTC            123.65499       124.30466       124.75166   \n",
              "2013-10-02      BTC            125.45500       123.65499       125.75850   \n",
              "2013-10-03      BTC            108.58483       125.45500       125.66566   \n",
              "2013-10-04      BTC            118.67466       108.58483       118.67500   \n",
              "2013-10-05      BTC            121.33866       118.67466       121.93633   \n",
              "2013-10-06      BTC            120.65533       121.33866       121.85216   \n",
              "2013-10-07      BTC            121.79500       120.65533       121.99166   \n",
              "2013-10-08      BTC            123.03300       121.79500       123.64016   \n",
              "2013-10-09      BTC            124.04900       123.03300       124.78350   \n",
              "2013-10-10      BTC            125.96116       124.04900       128.01683   \n",
              "\n",
              "            24h Low (USD)  day_of_week  \n",
              "Date                                    \n",
              "2013-10-01      122.56349            1  \n",
              "2013-10-02      123.63383            2  \n",
              "2013-10-03       83.32833            3  \n",
              "2013-10-04      107.05816            4  \n",
              "2013-10-05      118.00566            5  \n",
              "2013-10-06      120.55450            6  \n",
              "2013-10-07      120.43199            0  \n",
              "2013-10-08      121.35066            1  \n",
              "2013-10-09      122.59266            2  \n",
              "2013-10-10      123.81966            3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6402f2c-14ce-4884-a532-26dec0e1928b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>124.30466</td>\n",
              "      <td>124.75166</td>\n",
              "      <td>122.56349</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>125.75850</td>\n",
              "      <td>123.63383</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>125.66566</td>\n",
              "      <td>83.32833</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>118.67500</td>\n",
              "      <td>107.05816</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>121.93633</td>\n",
              "      <td>118.00566</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-06</th>\n",
              "      <td>BTC</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>121.85216</td>\n",
              "      <td>120.55450</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.99166</td>\n",
              "      <td>120.43199</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>123.64016</td>\n",
              "      <td>121.35066</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>BTC</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>124.78350</td>\n",
              "      <td>122.59266</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.96116</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>128.01683</td>\n",
              "      <td>123.81966</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6402f2c-14ce-4884-a532-26dec0e1928b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6402f2c-14ce-4884-a532-26dec0e1928b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6402f2c-14ce-4884-a532-26dec0e1928b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6860a853-78d3-4b2f-80b0-816e680661fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6860a853-78d3-4b2f-80b0-816e680661fb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6860a853-78d3-4b2f-80b0-816e680661fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the hyper parameters\n",
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "bitcoin_prices_windowed['day_of_week'] = bitcoin_prices_windowed.index.dayofweek"
      ],
      "metadata": {
        "id": "DHJviRsOOb0v"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting three kinds of data (univariate , multivariate and the day of week)\n",
        "\n",
        "# Univariate data\n",
        "full_windows , full_labels = make_windows_scaled(prices)\n",
        "train_windows , test_windows , train_labels , test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "# Multivaritate dat\n",
        "X = bitcoin_prices_windowed.dropna().drop('Price' , axis = 1).astype(np.float32)\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = bitcoin_prices_windowed.dropna()['Price'].astype(np.float32)\n",
        "\n",
        "# Day of week\n",
        "day_of_week = bitcoin_prices_windowed.dropna()['day_of_week'].to_list()"
      ],
      "metadata": {
        "id": "EbYA3bayPIbM"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shapes\n",
        "print(full_windows.shape , full_labels.shape)\n",
        "print(X.shape , y.shape)\n",
        "print(len(day_of_week))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j5oSii4Pj8F",
        "outputId": "3cfb793f-fad2-4692-9fe7-59b4c690eb65"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2780, 7) (2780, 1)\n",
            "(2780, 9) (2780,)\n",
            "2780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the multivariate and the day_of_week to train and test splits\n",
        "split_size = int(len(X) * 0.8)\n",
        "train_block_rewards , test_block_rewards = X[:split_size] , X[split_size:]\n",
        "train_days , test_days = day_of_week[:split_size] , day_of_week[split_size:]\n",
        "\n",
        "len(train_block_rewards), len(train_days) , len(test_block_rewards) , len(test_days)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVMymIToPnYt",
        "outputId": "1b6e58ae-c332-414b-f61f-f2c11d7a9bbb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2224, 556, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a performant dataset for train and test\n",
        "\n",
        "train_data_tribid = tf.data.Dataset.from_tensor_slices((train_windows ,\n",
        "                                                        train_block_rewards ,\n",
        "                                                        train_days))\n",
        "\n",
        "train_labels_tribid = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "\n",
        "# The test/val split\n",
        "test_data_tribid = tf.data.Dataset.from_tensor_slices((test_windows ,\n",
        "                                                       test_block_rewards ,\n",
        "                                                       test_days))\n",
        "\n",
        "test_labels_tribid = tf.data.Dataset.from_tensor_slices(test_labels)\n",
        "\n",
        "# Zipping the data and labels into one complete dataset\n",
        "tribid_train_ds = tf.data.Dataset.zip((train_data_tribid , train_labels_tribid))\n",
        "tribid_test_ds = tf.data.Dataset.zip((test_data_tribid , test_labels_tribid))\n",
        "\n",
        "# Applying prefetch and batching the dataset\n",
        "tribid_train_ds = tribid_train_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "tribid_test_ds = tribid_test_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "tribid_train_ds ,tribid_test_ds\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EgAj5mNPpR5",
        "outputId": "60c9980d-c0ea-4dfb-e927-4039797af406"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None)), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>,\n",
              " <_PrefetchDataset element_spec=((TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None)), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a tribid model\n",
        "\n",
        "input_windows = layers.Input(shape = (7,) , dtype=tf.float64 , name='Window Inputs')\n",
        "exp_layer_1 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_windows)\n",
        "conv1 = layers.Conv1D(filters= 32 , kernel_size=5 , padding='causal' , activation= 'relu')(exp_layer_1)\n",
        "window_model = tf.keras.Model(input_windows , conv1 , name = 'Windowed model')\n",
        "\n",
        "input_blocks = layers.Input(shape = (9,) , dtype= tf.float32 , name ='Block rewards input')\n",
        "exp_layer_2 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_blocks)\n",
        "conv2 = layers.Conv1D(filters = 32 , kernel_size= 5 , activation= 'relu' , padding = 'causal')(exp_layer_2)\n",
        "block_model = tf.keras.Model(input_blocks , conv2 , name = 'Block rewards model')\n",
        "\n",
        "\n",
        "# Use expand dims to match the same shape output (None , 1 , 128)\n",
        "# whereas without expand dims it would be (None , 128)\n",
        "input_days = layers.Input(shape= (1,) , dtype = tf.int32 , name ='Days of week Input')\n",
        "exp_layer_3 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_days)\n",
        "dense = layers.Dense(128 , activation= 'relu')(exp_layer_3)\n",
        "days_model = tf.keras.Model(input_days , dense , name = 'Days Model')\n",
        "\n",
        "# Concatenating the inputs\n",
        "concat = layers.Concatenate(name = 'combined_outputs' )([window_model.output ,\n",
        "                                                           block_model.output ,\n",
        "                                                           days_model.output])\n",
        "\n",
        "# Creating the output layer\n",
        "dropout = layers.Dropout(0.4)(concat)\n",
        "output_layer = layers.Dense(1 , activation = 'linear')(dropout)\n",
        "\n",
        "# Putting everything into a model\n",
        "tribid_model = tf.keras.Model(inputs = [window_model.input ,\n",
        "                                        block_model.input ,\n",
        "                                        days_model.input] ,\n",
        "                              outputs = output_layer)\n",
        "tribid_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkwGp-6sPxtG",
        "outputId": "d28c4bd7-785e-4a73-9c1f-5fa99b34ad82"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Window Inputs (InputLayer)     [(None, 7)]          0           []                               \n",
            "                                                                                                  \n",
            " Block rewards input (InputLaye  [(None, 9)]         0           []                               \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " Days of week Input (InputLayer  [(None, 1)]         0           []                               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 7)         0           ['Window Inputs[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 9)         0           ['Block rewards input[0][0]']    \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1)         0           ['Days of week Input[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 1, 32)        1152        ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 1, 32)        1472        ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense_72 (Dense)               (None, 1, 128)       256         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " combined_outputs (Concatenate)  (None, 1, 192)      0           ['conv1d[0][0]',                 \n",
            "                                                                  'conv1d_1[0][0]',               \n",
            "                                                                  'dense_72[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1, 192)       0           ['combined_outputs[0][0]']       \n",
            "                                                                                                  \n",
            " dense_73 (Dense)               (None, 1, 1)         193         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compiling and fitting the model\n",
        "tribid_model.compile(loss = 'mae' ,\n",
        "                     optimizer = 'adam' , metrics = ['mae'])\n",
        "\n",
        "# Fitting the model\n",
        "tribid_model.fit(tribid_train_ds ,\n",
        "                 epochs = 20,\n",
        "                 validation_data = tribid_test_ds , verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBAp-f15QBQZ",
        "outputId": "6716f92d-716a-489f-c299-6722569d223f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "18/18 - 10s - loss: 153.3654 - mae: 153.3654 - val_loss: 113.2260 - val_mae: 113.2260 - 10s/epoch - 531ms/step\n",
            "Epoch 2/20\n",
            "18/18 - 0s - loss: 88.0203 - mae: 88.0203 - val_loss: 102.1489 - val_mae: 102.1489 - 99ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "18/18 - 0s - loss: 49.9560 - mae: 49.9560 - val_loss: 70.5158 - val_mae: 70.5158 - 95ms/epoch - 5ms/step\n",
            "Epoch 4/20\n",
            "18/18 - 0s - loss: 20.3920 - mae: 20.3920 - val_loss: 27.1207 - val_mae: 27.1207 - 95ms/epoch - 5ms/step\n",
            "Epoch 5/20\n",
            "18/18 - 0s - loss: 6.1926 - mae: 6.1926 - val_loss: 3.9875 - val_mae: 3.9875 - 95ms/epoch - 5ms/step\n",
            "Epoch 6/20\n",
            "18/18 - 0s - loss: 2.8190 - mae: 2.8190 - val_loss: 13.0529 - val_mae: 13.0529 - 111ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "18/18 - 0s - loss: 1.1746 - mae: 1.1746 - val_loss: 4.4684 - val_mae: 4.4684 - 104ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "18/18 - 0s - loss: 0.8138 - mae: 0.8138 - val_loss: 3.1562 - val_mae: 3.1562 - 98ms/epoch - 5ms/step\n",
            "Epoch 9/20\n",
            "18/18 - 0s - loss: 0.6148 - mae: 0.6148 - val_loss: 1.7554 - val_mae: 1.7554 - 98ms/epoch - 5ms/step\n",
            "Epoch 10/20\n",
            "18/18 - 0s - loss: 0.7111 - mae: 0.7111 - val_loss: 3.9021 - val_mae: 3.9021 - 91ms/epoch - 5ms/step\n",
            "Epoch 11/20\n",
            "18/18 - 0s - loss: 0.2527 - mae: 0.2527 - val_loss: 1.0118 - val_mae: 1.0118 - 91ms/epoch - 5ms/step\n",
            "Epoch 12/20\n",
            "18/18 - 0s - loss: 0.3296 - mae: 0.3296 - val_loss: 1.4313 - val_mae: 1.4313 - 100ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "18/18 - 0s - loss: 0.7827 - mae: 0.7827 - val_loss: 3.1258 - val_mae: 3.1258 - 101ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "18/18 - 0s - loss: 0.4360 - mae: 0.4360 - val_loss: 0.3736 - val_mae: 0.3736 - 107ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "18/18 - 0s - loss: 0.7508 - mae: 0.7508 - val_loss: 2.2853 - val_mae: 2.2853 - 98ms/epoch - 5ms/step\n",
            "Epoch 16/20\n",
            "18/18 - 0s - loss: 0.5187 - mae: 0.5187 - val_loss: 2.8387 - val_mae: 2.8387 - 107ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "18/18 - 0s - loss: 0.1944 - mae: 0.1944 - val_loss: 0.4718 - val_mae: 0.4718 - 97ms/epoch - 5ms/step\n",
            "Epoch 18/20\n",
            "18/18 - 0s - loss: 0.1521 - mae: 0.1521 - val_loss: 0.1712 - val_mae: 0.1712 - 94ms/epoch - 5ms/step\n",
            "Epoch 19/20\n",
            "18/18 - 0s - loss: 0.1694 - mae: 0.1694 - val_loss: 0.9026 - val_mae: 0.9026 - 101ms/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "18/18 - 0s - loss: 0.3126 - mae: 0.3126 - val_loss: 1.0317 - val_mae: 1.0317 - 109ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78a74d70ce50>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluating the model\n",
        "tribid_model.evaluate(tribid_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zryvyv-mTH-3",
        "outputId": "6802b723-9ec1-480d-ad93-46816b3fff93"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0317 - mae: 1.0317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0316517353057861, 1.0316517353057861]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Make prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for model_8.**\n",
        "\n",
        "**Things to do**\n",
        "\n",
        "* Train an ensemble model on the whole data.\n",
        "* Make one dataset (no test/valid) which will use to predict future forecasts of bitcoins.\n",
        "* Make a function that will take the number of iterations and different loss functions to train the model with."
      ],
      "metadata": {
        "id": "z_5s0limTMJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make one whole dataset (with the updated bitcoin prices 2014 - 2021)\n",
        "\n",
        "X_all = bitcoin_prices_windowed.drop(['Price' , 'block_reward' , 'day_of_week'] , axis = 1).dropna().to_numpy()\n",
        "y_all = bitcoin_prices_windowed.dropna()['Price'].to_numpy()\n",
        "\n",
        "whole_ds = tf.data.Dataset.from_tensor_slices((X_all , y_all))\n",
        "whole_ds = whole_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "whole_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjinGi4-Td7U",
        "outputId": "0cf52c7c-1fd1-4fba-eb0f-eeae40d901ef"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating the function\n",
        "\n",
        "def get_ensemble_models(horizon = HORIZON ,\n",
        "                        dataset = whole_ds ,\n",
        "                        num_iter = 10 ,\n",
        "                        num_epochs = 100 ,\n",
        "                        loss_fns = ['mae' , 'mse' , 'mape']):\n",
        "\n",
        "\n",
        "  # Make a empty list of the ensemble models\n",
        "  ensemble_models = []\n",
        "\n",
        "  # Create num_iter number of models per loss functions\n",
        "  for i in range(num_iter):\n",
        "    for loss_functions in loss_fns:\n",
        "      print(f'Optimizing model by reducing: {loss_functions} for {num_epochs} epochs, model number: {i}')\n",
        "\n",
        "      model = tf.keras.Sequential([\n",
        "          layers.Dense(128 , kernel_initializer='he_normal' , activation= 'relu'),\n",
        "          layers.Dense(128 , kernel_initializer= 'he_normal', activation= 'relu'),\n",
        "          layers.Dense(HORIZON)\n",
        "      ])\n",
        "\n",
        "      # Compiling the model\n",
        "      model.compile(loss = loss_functions ,\n",
        "                    optimizer = 'adam' , metrics = ['mae' , 'mse'])\n",
        "\n",
        "      # Fit the model\n",
        "      model.fit(dataset ,\n",
        "                epochs = num_epochs ,\n",
        "                verbose = 0,\n",
        "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
        "                                                            patience=200,\n",
        "                                                            restore_best_weights=True),\n",
        "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",\n",
        "                                                                patience=100,\n",
        "                                                                verbose=1)])\n",
        "\n",
        "      ensemble_models.append(model)\n",
        "\n",
        "  return ensemble_models"
      ],
      "metadata": {
        "id": "BG4LTJJ6Vn16"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the above function\n",
        "ensemble_models = get_ensemble_models(num_iter=5 , num_epochs= 1000 , horizon = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUgXlIJxVvoO",
        "outputId": "d81263df-93aa-4e27-ffac-3a47c17a8b6c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing model by reducing: mae for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 364: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 423: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 523: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 343: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 282: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 579: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 498: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 627: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 728: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 229: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 366: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 596: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 305: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 406: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 510: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "\n",
            "Epoch 618: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "\n",
            "Epoch 719: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "\n",
            "Epoch 819: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "\n",
            "Epoch 919: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 384: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 502: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 446: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 347: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 447: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 365: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 508: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 439: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 404: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 512: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 613: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Making future forecastts of Bitcoins (using the whole data)\n",
        "def make_future_forecast(values , model_list , into_future , window_size):\n",
        "\n",
        "  future_forecast = []\n",
        "  last_window = values[-window_size:]\n",
        "\n",
        "  for _ in range(into_future):\n",
        "    for model in model_list:\n",
        "\n",
        "      future_pred = model.predict(tf.expand_dims(last_window, axis= 0))\n",
        "      #future_pred = model.predict(last_window)\n",
        "      print(f'Predicing on: \\n {last_window} --> Prediction: {tf.squeeze(future_pred).numpy()}\\n')\n",
        "\n",
        "      future_forecast.append(tf.squeeze(future_pred).numpy())\n",
        "\n",
        "      # Update the last window\n",
        "      last_window = np.append(last_window , future_pred)[-window_size:]\n",
        "  return future_forecast"
      ],
      "metadata": {
        "id": "D42k_P3FVx-O"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the future forecast\n",
        "future_forecast = make_future_forecast(y_all , ensemble_models , into_future= 14 , window_size = 7 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVH_zMPPWGem",
        "outputId": "645f9963-59b2-4887-87ff-e277c9ec6133"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "Predicing on: \n",
            " [56573.5554719  52147.82118698 49764.1320816  50032.69313676\n",
            " 47885.62525472 45604.61575361 43144.47129086] --> Prediction: 56018.12109375\n",
            "\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Predicing on: \n",
            " [52147.82118698 49764.1320816  50032.69313676 47885.62525472\n",
            " 45604.61575361 43144.47129086 56018.12109375] --> Prediction: 51284.5546875\n",
            "\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Predicing on: \n",
            " [49764.1320816  50032.69313676 47885.62525472 45604.61575361\n",
            " 43144.47129086 56018.12109375 51284.5546875 ] --> Prediction: 49752.953125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 22 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78a74f483370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n",
            "Predicing on: \n",
            " [50032.69313676 47885.62525472 45604.61575361 43144.47129086\n",
            " 56018.12109375 51284.5546875  49752.953125  ] --> Prediction: 50164.03515625\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78a74f04c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 58ms/step\n",
            "Predicing on: \n",
            " [47885.62525472 45604.61575361 43144.47129086 56018.12109375\n",
            " 51284.5546875  49752.953125   50164.03515625] --> Prediction: 48305.703125\n",
            "\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Predicing on: \n",
            " [45604.61575361 43144.47129086 56018.12109375 51284.5546875\n",
            " 49752.953125   50164.03515625 48305.703125  ] --> Prediction: 45464.23046875\n",
            "\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Predicing on: \n",
            " [43144.47129086 56018.12109375 51284.5546875  49752.953125\n",
            " 50164.03515625 48305.703125   45464.23046875] --> Prediction: 45313.40625\n",
            "\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Predicing on: \n",
            " [56018.12109375 51284.5546875  49752.953125   50164.03515625\n",
            " 48305.703125   45464.23046875 45313.40625   ] --> Prediction: 55963.47265625\n",
            "\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Predicing on: \n",
            " [51284.5546875  49752.953125   50164.03515625 48305.703125\n",
            " 45464.23046875 45313.40625    55963.47265625] --> Prediction: 50601.421875\n",
            "\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Predicing on: \n",
            " [49752.953125   50164.03515625 48305.703125   45464.23046875\n",
            " 45313.40625    55963.47265625 50601.421875  ] --> Prediction: 51315.47265625\n",
            "\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Predicing on: \n",
            " [50164.03515625 48305.703125   45464.23046875 45313.40625\n",
            " 55963.47265625 50601.421875   51315.47265625] --> Prediction: 49946.14453125\n",
            "\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Predicing on: \n",
            " [48305.703125   45464.23046875 45313.40625    55963.47265625\n",
            " 50601.421875   51315.47265625 49946.14453125] --> Prediction: 47735.3515625\n",
            "\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Predicing on: \n",
            " [45464.23046875 45313.40625    55963.47265625 50601.421875\n",
            " 51315.47265625 49946.14453125 47735.3515625 ] --> Prediction: 45246.16796875\n",
            "\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Predicing on: \n",
            " [45313.40625    55963.47265625 50601.421875   51315.47265625\n",
            " 49946.14453125 47735.3515625  45246.16796875] --> Prediction: 48819.5390625\n",
            "\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Predicing on: \n",
            " [55963.47265625 50601.421875   51315.47265625 49946.14453125\n",
            " 47735.3515625  45246.16796875 48819.5390625 ] --> Prediction: 55349.96484375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [50601.421875   51315.47265625 49946.14453125 47735.3515625\n",
            " 45246.16796875 48819.5390625  55349.96484375] --> Prediction: 49855.81640625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51315.47265625 49946.14453125 47735.3515625  45246.16796875\n",
            " 48819.5390625  55349.96484375 49855.81640625] --> Prediction: 52146.81640625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [49946.14453125 47735.3515625  45246.16796875 48819.5390625\n",
            " 55349.96484375 49855.81640625 52146.81640625] --> Prediction: 49746.2421875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [47735.3515625  45246.16796875 48819.5390625  55349.96484375\n",
            " 49855.81640625 52146.81640625 49746.2421875 ] --> Prediction: 46761.984375\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [45246.16796875 48819.5390625  55349.96484375 49855.81640625\n",
            " 52146.81640625 49746.2421875  46761.984375  ] --> Prediction: 46070.5625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [48819.5390625  55349.96484375 49855.81640625 52146.81640625\n",
            " 49746.2421875  46761.984375   46070.5625    ] --> Prediction: 49104.73828125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [55349.96484375 49855.81640625 52146.81640625 49746.2421875\n",
            " 46761.984375   46070.5625     49104.73828125] --> Prediction: 54931.32421875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [49855.81640625 52146.81640625 49746.2421875  46761.984375\n",
            " 46070.5625     49104.73828125 54931.32421875] --> Prediction: 50659.16796875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [52146.81640625 49746.2421875  46761.984375   46070.5625\n",
            " 49104.73828125 54931.32421875 50659.16796875] --> Prediction: 52247.7421875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [49746.2421875  46761.984375   46070.5625     49104.73828125\n",
            " 54931.32421875 50659.16796875 52247.7421875 ] --> Prediction: 48738.6171875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [46761.984375   46070.5625     49104.73828125 54931.32421875\n",
            " 50659.16796875 52247.7421875  48738.6171875 ] --> Prediction: 46638.69921875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [46070.5625     49104.73828125 54931.32421875 50659.16796875\n",
            " 52247.7421875  48738.6171875  46638.69921875] --> Prediction: 45164.12109375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [49104.73828125 54931.32421875 50659.16796875 52247.7421875\n",
            " 48738.6171875  46638.69921875 45164.12109375] --> Prediction: 49496.1484375\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [54931.32421875 50659.16796875 52247.7421875  48738.6171875\n",
            " 46638.69921875 45164.12109375 49496.1484375 ] --> Prediction: 55119.609375\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicing on: \n",
            " [50659.16796875 52247.7421875  48738.6171875  46638.69921875\n",
            " 45164.12109375 49496.1484375  55119.609375  ] --> Prediction: 50655.80078125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [52247.7421875  48738.6171875  46638.69921875 45164.12109375\n",
            " 49496.1484375  55119.609375   50655.80078125] --> Prediction: 53434.36328125\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [48738.6171875  46638.69921875 45164.12109375 49496.1484375\n",
            " 55119.609375   50655.80078125 53434.36328125] --> Prediction: 48230.03515625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46638.69921875 45164.12109375 49496.1484375  55119.609375\n",
            " 50655.80078125 53434.36328125 48230.03515625] --> Prediction: 46743.6484375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [45164.12109375 49496.1484375  55119.609375   50655.80078125\n",
            " 53434.36328125 48230.03515625 46743.6484375 ] --> Prediction: 46314.5546875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [49496.1484375  55119.609375   50655.80078125 53434.36328125\n",
            " 48230.03515625 46743.6484375  46314.5546875 ] --> Prediction: 50521.9453125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [55119.609375   50655.80078125 53434.36328125 48230.03515625\n",
            " 46743.6484375  46314.5546875  50521.9453125 ] --> Prediction: 54838.31640625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [50655.80078125 53434.36328125 48230.03515625 46743.6484375\n",
            " 46314.5546875  50521.9453125  54838.31640625] --> Prediction: 50792.078125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [53434.36328125 48230.03515625 46743.6484375  46314.5546875\n",
            " 50521.9453125  54838.31640625 50792.078125  ] --> Prediction: 54019.09765625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [48230.03515625 46743.6484375  46314.5546875  50521.9453125\n",
            " 54838.31640625 50792.078125   54019.09765625] --> Prediction: 47854.53515625\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Predicing on: \n",
            " [46743.6484375  46314.5546875  50521.9453125  54838.31640625\n",
            " 50792.078125   54019.09765625 47854.53515625] --> Prediction: 47190.8359375\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicing on: \n",
            " [46314.5546875  50521.9453125  54838.31640625 50792.078125\n",
            " 54019.09765625 47854.53515625 47190.8359375 ] --> Prediction: 46800.16015625\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [50521.9453125  54838.31640625 50792.078125   54019.09765625\n",
            " 47854.53515625 47190.8359375  46800.16015625] --> Prediction: 49977.01953125\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Predicing on: \n",
            " [54838.31640625 50792.078125   54019.09765625 47854.53515625\n",
            " 47190.8359375  46800.16015625 49977.01953125] --> Prediction: 54698.171875\n",
            "\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicing on: \n",
            " [50792.078125   54019.09765625 47854.53515625 47190.8359375\n",
            " 46800.16015625 49977.01953125 54698.171875  ] --> Prediction: 52535.21875\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [54019.09765625 47854.53515625 47190.8359375  46800.16015625\n",
            " 49977.01953125 54698.171875   52535.21875   ] --> Prediction: 53696.36328125\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicing on: \n",
            " [47854.53515625 47190.8359375  46800.16015625 49977.01953125\n",
            " 54698.171875   52535.21875    53696.36328125] --> Prediction: 47653.5703125\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicing on: \n",
            " [47190.8359375  46800.16015625 49977.01953125 54698.171875\n",
            " 52535.21875    53696.36328125 47653.5703125 ] --> Prediction: 47191.078125\n",
            "\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Predicing on: \n",
            " [46800.16015625 49977.01953125 54698.171875   52535.21875\n",
            " 53696.36328125 47653.5703125  47191.078125  ] --> Prediction: 46777.265625\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicing on: \n",
            " [49977.01953125 54698.171875   52535.21875    53696.36328125\n",
            " 47653.5703125  47191.078125   46777.265625  ] --> Prediction: 50924.0390625\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [54698.171875   52535.21875    53696.36328125 47653.5703125\n",
            " 47191.078125   46777.265625   50924.0390625 ] --> Prediction: 54431.25\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicing on: \n",
            " [52535.21875    53696.36328125 47653.5703125  47191.078125\n",
            " 46777.265625   50924.0390625  54431.25      ] --> Prediction: 51850.73046875\n",
            "\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Predicing on: \n",
            " [53696.36328125 47653.5703125  47191.078125   46777.265625\n",
            " 50924.0390625  54431.25       51850.73046875] --> Prediction: 53388.86328125\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicing on: \n",
            " [47653.5703125  47191.078125   46777.265625   50924.0390625\n",
            " 54431.25       51850.73046875 53388.86328125] --> Prediction: 47125.3359375\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicing on: \n",
            " [47191.078125   46777.265625   50924.0390625  54431.25\n",
            " 51850.73046875 53388.86328125 47125.3359375 ] --> Prediction: 47000.02734375\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Predicing on: \n",
            " [46777.265625   50924.0390625  54431.25       51850.73046875\n",
            " 53388.86328125 47125.3359375  47000.02734375] --> Prediction: 47663.421875\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Predicing on: \n",
            " [50924.0390625  54431.25       51850.73046875 53388.86328125\n",
            " 47125.3359375  47000.02734375 47663.421875  ] --> Prediction: 51220.1015625\n",
            "\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicing on: \n",
            " [54431.25       51850.73046875 53388.86328125 47125.3359375\n",
            " 47000.02734375 47663.421875   51220.1015625 ] --> Prediction: 53635.9921875\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [51850.73046875 53388.86328125 47125.3359375  47000.02734375\n",
            " 47663.421875   51220.1015625  53635.9921875 ] --> Prediction: 51285.59765625\n",
            "\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicing on: \n",
            " [53388.86328125 47125.3359375  47000.02734375 47663.421875\n",
            " 51220.1015625  53635.9921875  51285.59765625] --> Prediction: 52631.65625\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicing on: \n",
            " [47125.3359375  47000.02734375 47663.421875   51220.1015625\n",
            " 53635.9921875  51285.59765625 52631.65625   ] --> Prediction: 46933.31640625\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [47000.02734375 47663.421875   51220.1015625  53635.9921875\n",
            " 51285.59765625 52631.65625    46933.31640625] --> Prediction: 46670.55859375\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [47663.421875   51220.1015625  53635.9921875  51285.59765625\n",
            " 52631.65625    46933.31640625 46670.55859375] --> Prediction: 47900.53125\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicing on: \n",
            " [51220.1015625  53635.9921875  51285.59765625 52631.65625\n",
            " 46933.31640625 46670.55859375 47900.53125   ] --> Prediction: 51438.14453125\n",
            "\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Predicing on: \n",
            " [53635.9921875  51285.59765625 52631.65625    46933.31640625\n",
            " 46670.55859375 47900.53125    51438.14453125] --> Prediction: 53761.25\n",
            "\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Predicing on: \n",
            " [51285.59765625 52631.65625    46933.31640625 46670.55859375\n",
            " 47900.53125    51438.14453125 53761.25      ] --> Prediction: 51590.4140625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [52631.65625    46933.31640625 46670.55859375 47900.53125\n",
            " 51438.14453125 53761.25       51590.4140625 ] --> Prediction: 52019.06640625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [46933.31640625 46670.55859375 47900.53125    51438.14453125\n",
            " 53761.25       51590.4140625  52019.06640625] --> Prediction: 46197.8828125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [46670.55859375 47900.53125    51438.14453125 53761.25\n",
            " 51590.4140625  52019.06640625 46197.8828125 ] --> Prediction: 46469.31640625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [47900.53125    51438.14453125 53761.25       51590.4140625\n",
            " 52019.06640625 46197.8828125  46469.31640625] --> Prediction: 48138.70703125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [51438.14453125 53761.25       51590.4140625  52019.06640625\n",
            " 46197.8828125  46469.31640625 48138.70703125] --> Prediction: 52228.51171875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [53761.25       51590.4140625  52019.06640625 46197.8828125\n",
            " 46469.31640625 48138.70703125 52228.51171875] --> Prediction: 54362.06640625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51590.4140625  52019.06640625 46197.8828125  46469.31640625\n",
            " 48138.70703125 52228.51171875 54362.06640625] --> Prediction: 50396.74609375\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [52019.06640625 46197.8828125  46469.31640625 48138.70703125\n",
            " 52228.51171875 54362.06640625 50396.74609375] --> Prediction: 51833.44140625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46197.8828125  46469.31640625 48138.70703125 52228.51171875\n",
            " 54362.06640625 50396.74609375 51833.44140625] --> Prediction: 46188.6171875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [46469.31640625 48138.70703125 52228.51171875 54362.06640625\n",
            " 50396.74609375 51833.44140625 46188.6171875 ] --> Prediction: 46512.55078125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [48138.70703125 52228.51171875 54362.06640625 50396.74609375\n",
            " 51833.44140625 46188.6171875  46512.55078125] --> Prediction: 48966.2109375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [52228.51171875 54362.06640625 50396.74609375 51833.44140625\n",
            " 46188.6171875  46512.55078125 48966.2109375 ] --> Prediction: 52820.3984375\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [54362.06640625 50396.74609375 51833.44140625 46188.6171875\n",
            " 46512.55078125 48966.2109375  52820.3984375 ] --> Prediction: 54207.5859375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [50396.74609375 51833.44140625 46188.6171875  46512.55078125\n",
            " 48966.2109375  52820.3984375  54207.5859375 ] --> Prediction: 51167.765625\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [51833.44140625 46188.6171875  46512.55078125 48966.2109375\n",
            " 52820.3984375  54207.5859375  51167.765625  ] --> Prediction: 51919.31640625\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicing on: \n",
            " [46188.6171875  46512.55078125 48966.2109375  52820.3984375\n",
            " 54207.5859375  51167.765625   51919.31640625] --> Prediction: 46283.12109375\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicing on: \n",
            " [46512.55078125 48966.2109375  52820.3984375  54207.5859375\n",
            " 51167.765625   51919.31640625 46283.12109375] --> Prediction: 46894.84765625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [48966.2109375  52820.3984375  54207.5859375  51167.765625\n",
            " 51919.31640625 46283.12109375 46894.84765625] --> Prediction: 49214.91015625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [52820.3984375  54207.5859375  51167.765625   51919.31640625\n",
            " 46283.12109375 46894.84765625 49214.91015625] --> Prediction: 52923.171875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [54207.5859375  51167.765625   51919.31640625 46283.12109375\n",
            " 46894.84765625 49214.91015625 52923.171875  ] --> Prediction: 53085.4140625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [51167.765625   51919.31640625 46283.12109375 46894.84765625\n",
            " 49214.91015625 52923.171875   53085.4140625 ] --> Prediction: 51484.16015625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [51919.31640625 46283.12109375 46894.84765625 49214.91015625\n",
            " 52923.171875   53085.4140625  51484.16015625] --> Prediction: 50869.14453125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [46283.12109375 46894.84765625 49214.91015625 52923.171875\n",
            " 53085.4140625  51484.16015625 50869.14453125] --> Prediction: 45706.52734375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [46894.84765625 49214.91015625 52923.171875   53085.4140625\n",
            " 51484.16015625 50869.14453125 45706.52734375] --> Prediction: 47082.74609375\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicing on: \n",
            " [49214.91015625 52923.171875   53085.4140625  51484.16015625\n",
            " 50869.14453125 45706.52734375 47082.74609375] --> Prediction: 49128.94921875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [52923.171875   53085.4140625  51484.16015625 50869.14453125\n",
            " 45706.52734375 47082.74609375 49128.94921875] --> Prediction: 54247.20703125\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [53085.4140625  51484.16015625 50869.14453125 45706.52734375\n",
            " 47082.74609375 49128.94921875 54247.20703125] --> Prediction: 53528.57421875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [51484.16015625 50869.14453125 45706.52734375 47082.74609375\n",
            " 49128.94921875 54247.20703125 53528.57421875] --> Prediction: 51283.078125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [50869.14453125 45706.52734375 47082.74609375 49128.94921875\n",
            " 54247.20703125 53528.57421875 51283.078125  ] --> Prediction: 49993.91796875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [45706.52734375 47082.74609375 49128.94921875 54247.20703125\n",
            " 53528.57421875 51283.078125   49993.91796875] --> Prediction: 45506.5703125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [47082.74609375 49128.94921875 54247.20703125 53528.57421875\n",
            " 51283.078125   49993.91796875 45506.5703125 ] --> Prediction: 47289.40234375\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [49128.94921875 54247.20703125 53528.57421875 51283.078125\n",
            " 49993.91796875 45506.5703125  47289.40234375] --> Prediction: 49761.1328125\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [54247.20703125 53528.57421875 51283.078125   49993.91796875\n",
            " 45506.5703125  47289.40234375 49761.1328125 ] --> Prediction: 55024.51953125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [53528.57421875 51283.078125   49993.91796875 45506.5703125\n",
            " 47289.40234375 49761.1328125  55024.51953125] --> Prediction: 52928.93359375\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [51283.078125   49993.91796875 45506.5703125  47289.40234375\n",
            " 49761.1328125  55024.51953125 52928.93359375] --> Prediction: 51602.390625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [49993.91796875 45506.5703125  47289.40234375 49761.1328125\n",
            " 55024.51953125 52928.93359375 51602.390625  ] --> Prediction: 48979.703125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [45506.5703125  47289.40234375 49761.1328125  55024.51953125\n",
            " 52928.93359375 51602.390625   48979.703125  ] --> Prediction: 45248.7578125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [47289.40234375 49761.1328125  55024.51953125 52928.93359375\n",
            " 51602.390625   48979.703125   45248.7578125 ] --> Prediction: 47010.58203125\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [49761.1328125  55024.51953125 52928.93359375 51602.390625\n",
            " 48979.703125   45248.7578125  47010.58203125] --> Prediction: 50787.27734375\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [55024.51953125 52928.93359375 51602.390625   48979.703125\n",
            " 45248.7578125  47010.58203125 50787.27734375] --> Prediction: 54689.87890625\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [52928.93359375 51602.390625   48979.703125   45248.7578125\n",
            " 47010.58203125 50787.27734375 54689.87890625] --> Prediction: 51285.765625\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicing on: \n",
            " [51602.390625   48979.703125   45248.7578125  47010.58203125\n",
            " 50787.27734375 54689.87890625 51285.765625  ] --> Prediction: 52146.41015625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [48979.703125   45248.7578125  47010.58203125 50787.27734375\n",
            " 54689.87890625 51285.765625   52146.41015625] --> Prediction: 48875.8671875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [45248.7578125  47010.58203125 50787.27734375 54689.87890625\n",
            " 51285.765625   52146.41015625 48875.8671875 ] --> Prediction: 45142.8046875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [47010.58203125 50787.27734375 54689.87890625 51285.765625\n",
            " 52146.41015625 48875.8671875  45142.8046875 ] --> Prediction: 47724.97265625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [50787.27734375 54689.87890625 51285.765625   52146.41015625\n",
            " 48875.8671875  45142.8046875  47724.97265625] --> Prediction: 50873.921875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [54689.87890625 51285.765625   52146.41015625 48875.8671875\n",
            " 45142.8046875  47724.97265625 50873.921875  ] --> Prediction: 54470.46484375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [51285.765625   52146.41015625 48875.8671875  45142.8046875\n",
            " 47724.97265625 50873.921875   54470.46484375] --> Prediction: 51894.8984375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [52146.41015625 48875.8671875  45142.8046875  47724.97265625\n",
            " 50873.921875   54470.46484375 51894.8984375 ] --> Prediction: 52157.2421875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [48875.8671875  45142.8046875  47724.97265625 50873.921875\n",
            " 54470.46484375 51894.8984375  52157.2421875 ] --> Prediction: 47507.8125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [45142.8046875  47724.97265625 50873.921875   54470.46484375\n",
            " 51894.8984375  52157.2421875  47507.8125    ] --> Prediction: 45873.94140625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [47724.97265625 50873.921875   54470.46484375 51894.8984375\n",
            " 52157.2421875  47507.8125     45873.94140625] --> Prediction: 46782.26171875\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicing on: \n",
            " [50873.921875   54470.46484375 51894.8984375  52157.2421875\n",
            " 47507.8125     45873.94140625 46782.26171875] --> Prediction: 51250.7109375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [54470.46484375 51894.8984375  52157.2421875  47507.8125\n",
            " 45873.94140625 46782.26171875 51250.7109375 ] --> Prediction: 54770.80859375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [51894.8984375  52157.2421875  47507.8125     45873.94140625\n",
            " 46782.26171875 51250.7109375  54770.80859375] --> Prediction: 51731.484375\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [52157.2421875  47507.8125     45873.94140625 46782.26171875\n",
            " 51250.7109375  54770.80859375 51731.484375  ] --> Prediction: 53290.7890625\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [47507.8125     45873.94140625 46782.26171875 51250.7109375\n",
            " 54770.80859375 51731.484375   53290.7890625 ] --> Prediction: 46566.5625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [45873.94140625 46782.26171875 51250.7109375  54770.80859375\n",
            " 51731.484375   53290.7890625  46566.5625    ] --> Prediction: 46163.8125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46782.26171875 51250.7109375  54770.80859375 51731.484375\n",
            " 53290.7890625  46566.5625     46163.8125    ] --> Prediction: 47065.1328125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51250.7109375  54770.80859375 51731.484375   53290.7890625\n",
            " 46566.5625     46163.8125     47065.1328125 ] --> Prediction: 52124.7890625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [54770.80859375 51731.484375   53290.7890625  46566.5625\n",
            " 46163.8125     47065.1328125  52124.7890625 ] --> Prediction: 54522.71484375\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicing on: \n",
            " [51731.484375   53290.7890625  46566.5625     46163.8125\n",
            " 47065.1328125  52124.7890625  54522.71484375] --> Prediction: 51642.61328125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [53290.7890625  46566.5625     46163.8125     47065.1328125\n",
            " 52124.7890625  54522.71484375 51642.61328125] --> Prediction: 53400.8515625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [46566.5625     46163.8125     47065.1328125  52124.7890625\n",
            " 54522.71484375 51642.61328125 53400.8515625 ] --> Prediction: 46121.3671875\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [46163.8125     47065.1328125  52124.7890625  54522.71484375\n",
            " 51642.61328125 53400.8515625  46121.3671875 ] --> Prediction: 46752.875\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [47065.1328125  52124.7890625  54522.71484375 51642.61328125\n",
            " 53400.8515625  46121.3671875  46752.875     ] --> Prediction: 47472.265625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [52124.7890625  54522.71484375 51642.61328125 53400.8515625\n",
            " 46121.3671875  46752.875      47472.265625  ] --> Prediction: 51641.26953125\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [54522.71484375 51642.61328125 53400.8515625  46121.3671875\n",
            " 46752.875      47472.265625   51641.26953125] --> Prediction: 54377.28125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51642.61328125 53400.8515625  46121.3671875  46752.875\n",
            " 47472.265625   51641.26953125 54377.28125   ] --> Prediction: 53166.046875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [53400.8515625  46121.3671875  46752.875      47472.265625\n",
            " 51641.26953125 54377.28125    53166.046875  ] --> Prediction: 52921.82421875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46121.3671875  46752.875      47472.265625   51641.26953125\n",
            " 54377.28125    53166.046875   52921.82421875] --> Prediction: 45590.05859375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46752.875      47472.265625   51641.26953125 54377.28125\n",
            " 53166.046875   52921.82421875 45590.05859375] --> Prediction: 46463.8125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [47472.265625   51641.26953125 54377.28125    53166.046875\n",
            " 52921.82421875 45590.05859375 46463.8125    ] --> Prediction: 47604.0625\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [51641.26953125 54377.28125    53166.046875   52921.82421875\n",
            " 45590.05859375 46463.8125     47604.0625    ] --> Prediction: 52631.26171875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [54377.28125    53166.046875   52921.82421875 45590.05859375\n",
            " 46463.8125     47604.0625     52631.26171875] --> Prediction: 54183.78515625\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [53166.046875   52921.82421875 45590.05859375 46463.8125\n",
            " 47604.0625     52631.26171875 54183.78515625] --> Prediction: 51943.79296875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [52921.82421875 45590.05859375 46463.8125     47604.0625\n",
            " 52631.26171875 54183.78515625 51943.79296875] --> Prediction: 52382.4296875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [45590.05859375 46463.8125     47604.0625     52631.26171875\n",
            " 54183.78515625 51943.79296875 52382.4296875 ] --> Prediction: 45047.26171875\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicing on: \n",
            " [46463.8125     47604.0625     52631.26171875 54183.78515625\n",
            " 51943.79296875 52382.4296875  45047.26171875] --> Prediction: 46368.39453125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [47604.0625     52631.26171875 54183.78515625 51943.79296875\n",
            " 52382.4296875  45047.26171875 46368.39453125] --> Prediction: 48839.09375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [52631.26171875 54183.78515625 51943.79296875 52382.4296875\n",
            " 45047.26171875 46368.39453125 48839.09375   ] --> Prediction: 53289.12109375\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [54183.78515625 51943.79296875 52382.4296875  45047.26171875\n",
            " 46368.39453125 48839.09375    53289.12109375] --> Prediction: 53485.35546875\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicing on: \n",
            " [51943.79296875 52382.4296875  45047.26171875 46368.39453125\n",
            " 48839.09375    53289.12109375 53485.35546875] --> Prediction: 51552.66015625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [52382.4296875  45047.26171875 46368.39453125 48839.09375\n",
            " 53289.12109375 53485.35546875 51552.66015625] --> Prediction: 50923.328125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [45047.26171875 46368.39453125 48839.09375    53289.12109375\n",
            " 53485.35546875 51552.66015625 50923.328125  ] --> Prediction: 45244.76171875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46368.39453125 48839.09375    53289.12109375 53485.35546875\n",
            " 51552.66015625 50923.328125   45244.76171875] --> Prediction: 45742.5859375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [48839.09375    53289.12109375 53485.35546875 51552.66015625\n",
            " 50923.328125   45244.76171875 45742.5859375 ] --> Prediction: 49401.58203125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [53289.12109375 53485.35546875 51552.66015625 50923.328125\n",
            " 45244.76171875 45742.5859375  49401.58203125] --> Prediction: 53490.1015625\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicing on: \n",
            " [53485.35546875 51552.66015625 50923.328125   45244.76171875\n",
            " 45742.5859375  49401.58203125 53490.1015625 ] --> Prediction: 53761.8828125\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicing on: \n",
            " [51552.66015625 50923.328125   45244.76171875 45742.5859375\n",
            " 49401.58203125 53490.1015625  53761.8828125 ] --> Prediction: 51671.078125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [50923.328125   45244.76171875 45742.5859375  49401.58203125\n",
            " 53490.1015625  53761.8828125  51671.078125  ] --> Prediction: 50645.81640625\n",
            "\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicing on: \n",
            " [45244.76171875 45742.5859375  49401.58203125 53490.1015625\n",
            " 53761.8828125  51671.078125   50645.81640625] --> Prediction: 44809.015625\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [45742.5859375  49401.58203125 53490.1015625  53761.8828125\n",
            " 51671.078125   50645.81640625 44809.015625  ] --> Prediction: 45788.72265625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [49401.58203125 53490.1015625  53761.8828125  51671.078125\n",
            " 50645.81640625 44809.015625   45788.72265625] --> Prediction: 49730.90234375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [53490.1015625  53761.8828125  51671.078125   50645.81640625\n",
            " 44809.015625   45788.72265625 49730.90234375] --> Prediction: 54011.4453125\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [53761.8828125  51671.078125   50645.81640625 44809.015625\n",
            " 45788.72265625 49730.90234375 54011.4453125 ] --> Prediction: 54206.796875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51671.078125   50645.81640625 44809.015625   45788.72265625\n",
            " 49730.90234375 54011.4453125  54206.796875  ] --> Prediction: 49910.94140625\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicing on: \n",
            " [50645.81640625 44809.015625   45788.72265625 49730.90234375\n",
            " 54011.4453125  54206.796875   49910.94140625] --> Prediction: 50635.98828125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [44809.015625   45788.72265625 49730.90234375 54011.4453125\n",
            " 54206.796875   49910.94140625 50635.98828125] --> Prediction: 45488.8125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [45788.72265625 49730.90234375 54011.4453125  54206.796875\n",
            " 49910.94140625 50635.98828125 45488.8125    ] --> Prediction: 45860.875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [49730.90234375 54011.4453125  54206.796875   49910.94140625\n",
            " 50635.98828125 45488.8125     45860.875     ] --> Prediction: 51414.56640625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [54011.4453125  54206.796875   49910.94140625 50635.98828125\n",
            " 45488.8125     45860.875      51414.56640625] --> Prediction: 54119.9921875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [54206.796875   49910.94140625 50635.98828125 45488.8125\n",
            " 45860.875      51414.56640625 54119.9921875 ] --> Prediction: 53935.8515625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [49910.94140625 50635.98828125 45488.8125     45860.875\n",
            " 51414.56640625 54119.9921875  53935.8515625 ] --> Prediction: 50488.4453125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [50635.98828125 45488.8125     45860.875      51414.56640625\n",
            " 54119.9921875  53935.8515625  50488.4453125 ] --> Prediction: 50528.4375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [45488.8125     45860.875      51414.56640625 54119.9921875\n",
            " 53935.8515625  50488.4453125  50528.4375    ] --> Prediction: 45525.66015625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [45860.875      51414.56640625 54119.9921875  53935.8515625\n",
            " 50488.4453125  50528.4375     45525.66015625] --> Prediction: 46551.4140625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51414.56640625 54119.9921875  53935.8515625  50488.4453125\n",
            " 50528.4375     45525.66015625 46551.4140625 ] --> Prediction: 51705.97265625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [54119.9921875  53935.8515625  50488.4453125  50528.4375\n",
            " 45525.66015625 46551.4140625  51705.97265625] --> Prediction: 53828.33203125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [53935.8515625  50488.4453125  50528.4375     45525.66015625\n",
            " 46551.4140625  51705.97265625 53828.33203125] --> Prediction: 52665.375\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [50488.4453125  50528.4375     45525.66015625 46551.4140625\n",
            " 51705.97265625 53828.33203125 52665.375     ] --> Prediction: 50472.82421875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [50528.4375     45525.66015625 46551.4140625  51705.97265625\n",
            " 53828.33203125 52665.375      50472.82421875] --> Prediction: 49811.9921875\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicing on: \n",
            " [45525.66015625 46551.4140625  51705.97265625 53828.33203125\n",
            " 52665.375      50472.82421875 49811.9921875 ] --> Prediction: 45164.734375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [46551.4140625  51705.97265625 53828.33203125 52665.375\n",
            " 50472.82421875 49811.9921875  45164.734375  ] --> Prediction: 47801.93359375\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [51705.97265625 53828.33203125 52665.375      50472.82421875\n",
            " 49811.9921875  45164.734375   47801.93359375] --> Prediction: 51712.453125\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [53828.33203125 52665.375      50472.82421875 49811.9921875\n",
            " 45164.734375   47801.93359375 51712.453125  ] --> Prediction: 54305.75\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [52665.375      50472.82421875 49811.9921875  45164.734375\n",
            " 47801.93359375 51712.453125   54305.75      ] --> Prediction: 53429.296875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [50472.82421875 49811.9921875  45164.734375   47801.93359375\n",
            " 51712.453125   54305.75       53429.296875  ] --> Prediction: 50395.84375\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicing on: \n",
            " [49811.9921875  45164.734375   47801.93359375 51712.453125\n",
            " 54305.75       53429.296875   50395.84375   ] --> Prediction: 48886.140625\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [45164.734375   47801.93359375 51712.453125   54305.75\n",
            " 53429.296875   50395.84375    48886.140625  ] --> Prediction: 45454.77734375\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [47801.93359375 51712.453125   54305.75       53429.296875\n",
            " 50395.84375    48886.140625   45454.77734375] --> Prediction: 48154.79296875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [51712.453125   54305.75       53429.296875   50395.84375\n",
            " 48886.140625   45454.77734375 48154.79296875] --> Prediction: 52287.36328125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [54305.75       53429.296875   50395.84375    48886.140625\n",
            " 45454.77734375 48154.79296875 52287.36328125] --> Prediction: 55019.27734375\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [53429.296875   50395.84375    48886.140625   45454.77734375\n",
            " 48154.79296875 52287.36328125 55019.27734375] --> Prediction: 52990.796875\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicing on: \n",
            " [50395.84375    48886.140625   45454.77734375 48154.79296875\n",
            " 52287.36328125 55019.27734375 52990.796875  ] --> Prediction: 50720.5234375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [48886.140625   45454.77734375 48154.79296875 52287.36328125\n",
            " 55019.27734375 52990.796875   50720.5234375 ] --> Prediction: 47936.25\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [45454.77734375 48154.79296875 52287.36328125 55019.27734375\n",
            " 52990.796875   50720.5234375  47936.25      ] --> Prediction: 44999.03125\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicing on: \n",
            " [48154.79296875 52287.36328125 55019.27734375 52990.796875\n",
            " 50720.5234375  47936.25       44999.03125   ] --> Prediction: 48107.57421875\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [52287.36328125 55019.27734375 52990.796875   50720.5234375\n",
            " 47936.25       44999.03125    48107.57421875] --> Prediction: 53365.34375\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [55019.27734375 52990.796875   50720.5234375  47936.25\n",
            " 44999.03125    48107.57421875 53365.34375   ] --> Prediction: 54631.90625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [52990.796875   50720.5234375  47936.25       44999.03125\n",
            " 48107.57421875 53365.34375    54631.90625   ] --> Prediction: 51349.859375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [50720.5234375  47936.25       44999.03125    48107.57421875\n",
            " 53365.34375    54631.90625    51349.859375  ] --> Prediction: 50787.4296875\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [47936.25       44999.03125    48107.57421875 53365.34375\n",
            " 54631.90625    51349.859375   50787.4296875 ] --> Prediction: 47829.50390625\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicing on: \n",
            " [44999.03125    48107.57421875 53365.34375    54631.90625\n",
            " 51349.859375   50787.4296875  47829.50390625] --> Prediction: 45114.2734375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [48107.57421875 53365.34375    54631.90625    51349.859375\n",
            " 50787.4296875  47829.50390625 45114.2734375 ] --> Prediction: 49016.14453125\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [53365.34375    54631.90625    51349.859375   50787.4296875\n",
            " 47829.50390625 45114.2734375  49016.14453125] --> Prediction: 53438.45703125\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicing on: \n",
            " [54631.90625    51349.859375   50787.4296875  47829.50390625\n",
            " 45114.2734375  49016.14453125 53438.45703125] --> Prediction: 54095.5625\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [51349.859375   50787.4296875  47829.50390625 45114.2734375\n",
            " 49016.14453125 53438.45703125 54095.5625    ] --> Prediction: 51625.46484375\n",
            "\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicing on: \n",
            " [50787.4296875  47829.50390625 45114.2734375  49016.14453125\n",
            " 53438.45703125 54095.5625     51625.46484375] --> Prediction: 50774.39453125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [47829.50390625 45114.2734375  49016.14453125 53438.45703125\n",
            " 54095.5625     51625.46484375 50774.39453125] --> Prediction: 46556.015625\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [45114.2734375  49016.14453125 53438.45703125 54095.5625\n",
            " 51625.46484375 50774.39453125 46556.015625  ] --> Prediction: 45837.609375\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [49016.14453125 53438.45703125 54095.5625     51625.46484375\n",
            " 50774.39453125 46556.015625   45837.609375  ] --> Prediction: 48207.41796875\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [53438.45703125 54095.5625     51625.46484375 50774.39453125\n",
            " 46556.015625   45837.609375   48207.41796875] --> Prediction: 53887.2734375\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [54095.5625     51625.46484375 50774.39453125 46556.015625\n",
            " 45837.609375   48207.41796875 53887.2734375 ] --> Prediction: 54230.296875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [51625.46484375 50774.39453125 46556.015625   45837.609375\n",
            " 48207.41796875 53887.2734375  54230.296875  ] --> Prediction: 51318.84765625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. For future predictions, try to make a prediction, retrain a model on the predictions, make a prediction, retrain a model, make a prediction, retrain a model, make a prediction (retrain a model each time a new prediction is made). Plot the results, how do they look compared to the future predictions where a model wasn’t retrained for every forecast (model_9)?**\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "1CJhh_ZNWOQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets code things at first without a loop and see how it foes\n",
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "# Building a model (You can replace it with any model)\n",
        "def get_model(horizon = HORIZON):\n",
        "    model = tf.keras.Sequential([\n",
        "            layers.Dense(128 , activation = 'relu'),\n",
        "            layers.Dense(128 , activation = 'relu'),\n",
        "            layers.Dense(horizon)\n",
        "        ])\n",
        "\n",
        "    model.compile(loss = tf.keras.losses.mae ,\n",
        "                  optimizer = tf.keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "p2FUQFsxW7Cr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. Making the data and labels for window size of 7 and horizon of 1\n",
        "full_windows , full_labels = make_windows(prices , window_size= WINDOW_SIZE , horizon= HORIZON)"
      ],
      "metadata": {
        "id": "eS_OTVVAXdUB"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making future forecastts of Bitcoins (using the whole data)\n",
        "def pred_model_run(values , X, model , into_future , window_size  , horizon, epochs ):\n",
        "\n",
        "  '''\n",
        "  This function train a model for every updated predictions.\n",
        "\n",
        "  Arguments:\n",
        "  ----------\n",
        "      - values --> labels / truth values. Bitcoin prices\n",
        "      - X --> Windowed data of the bitcoin prices (default window size is 7)\n",
        "      - model --> compiled model with default horizon 1\n",
        "      - into_future -->  how many time steps to predict in the future?\n",
        "      - window_size --> default is 7 (using the 7 days prices of bitcoin)\n",
        "      - horizon --> default is 1 (predicting the price of next day)\n",
        "\n",
        "  Returns:\n",
        "  --------\n",
        "      - model --> a model that has been trained on all the previous predictions + the data\n",
        "  '''\n",
        "\n",
        "  last_window = values[-window_size:]\n",
        "  X_all = X\n",
        "  y_all = values\n",
        "  for _ in range(into_future):\n",
        "\n",
        "      # Each time the model is trained for 5 epochs with the updated data\n",
        "      model.fit(x = X_all , y = y_all , epochs = epochs , verbose = 0)\n",
        "\n",
        "      future_pred = model.predict(tf.expand_dims(last_window, axis= 0))\n",
        "      #future_pred = model.predict(last_window)\n",
        "      print(f'Predicing on: \\n {last_window} --> Prediction: {tf.squeeze(future_pred).numpy()}\\n')\n",
        "\n",
        "      future_forecast.append(tf.squeeze(future_pred).numpy())\n",
        "      #values = np.append(values , tf.squeeze(future_pred).numpy())\n",
        "      for i in range(0 , len(X_all)):\n",
        "        x = X_all[i][1:]  # removing the 0th index of the X window ()\n",
        "        y = y_all[1:] # removing the 0th index  of y\n",
        "        X = np.append(x , future_pred) # append the future pred at last to X window\n",
        "        values = np.append(y , future_pred) # appending the future pred to y\n",
        "\n",
        "      # Update the last window\n",
        "      last_window = np.append(last_window , future_pred)[-window_size:]\n",
        "\n",
        "\n",
        "  return model\n",
        ""
      ],
      "metadata": {
        "id": "ktoih2oyXkqi"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_windows.shape , X_all.shape , full_labels.shape , y_all.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyYdz0ITZPe9",
        "outputId": "8271bb02-1ea7-4128-d8b7-a908de2720f3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2780, 7), (2780, 7), (2780, 1), (2780,))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the above function\n",
        "trained_model = pred_model_run(values = tf.squeeze(full_labels) ,\n",
        "                               X = full_windows ,\n",
        "                               model = get_model(horizon = 1) ,\n",
        "                               window_size = WINDOW_SIZE ,\n",
        "                               horizon = HORIZON ,\n",
        "                               epochs = 10 ,\n",
        "                               into_future  =14 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRhg2bbgZTvk",
        "outputId": "6af2e126-10c1-464b-a454-398cfc73bd39"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n",
            "Predicing on: \n",
            " [56573.5554719  52147.82118698 49764.1320816  50032.69313676\n",
            " 47885.62525472 45604.61575361 43144.47129086] --> Prediction: 43244.7421875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [52147.82118698 49764.1320816  50032.69313676 47885.62525472\n",
            " 45604.61575361 43144.47129086 43244.7421875 ] --> Prediction: 41692.8984375\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicing on: \n",
            " [49764.1320816  50032.69313676 47885.62525472 45604.61575361\n",
            " 43144.47129086 43244.7421875  41692.8984375 ] --> Prediction: 41201.66796875\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicing on: \n",
            " [50032.69313676 47885.62525472 45604.61575361 43144.47129086\n",
            " 43244.7421875  41692.8984375  41201.66796875] --> Prediction: 40764.30859375\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicing on: \n",
            " [47885.62525472 45604.61575361 43144.47129086 43244.7421875\n",
            " 41692.8984375  41201.66796875 40764.30859375] --> Prediction: 40252.48046875\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [45604.61575361 43144.47129086 43244.7421875  41692.8984375\n",
            " 41201.66796875 40764.30859375 40252.48046875] --> Prediction: 40002.6875\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicing on: \n",
            " [43144.47129086 43244.7421875  41692.8984375  41201.66796875\n",
            " 40764.30859375 40252.48046875 40002.6875    ] --> Prediction: 39616.91796875\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [43244.7421875  41692.8984375  41201.66796875 40764.30859375\n",
            " 40252.48046875 40002.6875     39616.91796875] --> Prediction: 39211.94140625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [41692.8984375  41201.66796875 40764.30859375 40252.48046875\n",
            " 40002.6875     39616.91796875 39211.94140625] --> Prediction: 39018.33984375\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [41201.66796875 40764.30859375 40252.48046875 40002.6875\n",
            " 39616.91796875 39211.94140625 39018.33984375] --> Prediction: 38568.8828125\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicing on: \n",
            " [40764.30859375 40252.48046875 40002.6875     39616.91796875\n",
            " 39211.94140625 39018.33984375 38568.8828125 ] --> Prediction: 38166.7890625\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [40252.48046875 40002.6875     39616.91796875 39211.94140625\n",
            " 39018.33984375 38568.8828125  38166.7890625 ] --> Prediction: 37709.76953125\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicing on: \n",
            " [40002.6875     39616.91796875 39211.94140625 39018.33984375\n",
            " 38568.8828125  38166.7890625  37709.76953125] --> Prediction: 37192.09375\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicing on: \n",
            " [39616.91796875 39211.94140625 39018.33984375 38568.8828125\n",
            " 38166.7890625  37709.76953125 37192.09375   ] --> Prediction: 37196.8203125\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying out new libraries\n",
        "# Installing facebooks kats lib\n",
        "pip install kats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "oBBJ3Sw4ZeVw",
        "outputId": "5db0067f-e536-447b-8662-24a61d8344db"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-83-16cd46852374>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install kats\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the TimeSerisData class from Kats\n",
        "from kats.consts import TimeSeriesData\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "2y14EYVWar2m",
        "outputId": "5ada0dfb-fd2e-4cb5-a07d-4e267ba3a380"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-171aafba5986>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing the TimeSerisData class from Kats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeSeriesData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kats'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Utils to work with Kats\n",
        "from dateutil import parser\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "zlI40K72a00w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a Dataset object with Kats\n",
        "ts_data = TimeSeriesData(time = bitcoin_prices_updated.index ,\n",
        "               value = bitcoin_prices_updated.Price)\n",
        "\n",
        "type(ts_data)\n",
        ""
      ],
      "metadata": {
        "id": "Ev-7AnIla2R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plotting the timeseries data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ts_data.plot(cols=['Price'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "45v_2rmJa5J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the prophet\n",
        "from kats.models.prophet import ProphetModel , ProphetParams\n",
        "\n",
        "# Creating a model param instance\n",
        "params = ProphetParams(seasonality_mode= 'multiplicative')\n",
        "\n",
        "# Create a prophet model instance (just like how we create an instance in sklearn)\n",
        "model = ProphetModel(ts_data , params)\n",
        "\n",
        "# Fitting the model\n",
        "model.fit()\n",
        "\n",
        "# Making predictions\n",
        "forecast = model.predict(steps= 1 , include_history= True , freq = '1W')"
      ],
      "metadata": {
        "id": "HD-0NMRWa7W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the bitcoin price for a day (Horizon = 1 )\n",
        "forecast.head(10)"
      ],
      "metadata": {
        "id": "5Mgyyk5gbAaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the things we need\n",
        "from kats.models.ensemble.ensemble import EnsembleParams , BaseModelParams\n",
        "from kats.models.ensemble.kats_ensemble import KatsEnsemble\n",
        "from kats.models import (\n",
        "    arima,\n",
        "    holtwinters ,\n",
        "    linear_model ,\n",
        "    prophet ,\n",
        "    quadratic_model ,\n",
        "    sarima ,\n",
        "    theta\n",
        ")"
      ],
      "metadata": {
        "id": "-bae0zhUbEUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Defining the parameters of different models\n",
        "model_params = EnsembleParams(\n",
        "    [\n",
        "     BaseModelParams('arima' , arima.ARIMAParams(p = 1 , d=1 , q=1)) ,\n",
        "     BaseModelParams('sarima' ,\n",
        "                     sarima.SARIMAParams(\n",
        "                         p = 2 , d= 2 , q =1 , trend = 'ct' ,\n",
        "                     seasonal_order = (1, 0 ,1 ,12) , enforce_invertibility = False ,\n",
        "                     enforce_stationarity = False),\n",
        "     ),\n",
        "     BaseModelParams('prophet' , prophet.ProphetParams()) ,\n",
        "     BaseModelParams('linear' , linear_model.LinearModelParams()) ,\n",
        "     BaseModelParams('quadratic' , quadratic_model.QuadraticModelParams()),\n",
        "     BaseModelParams('theta' , theta.ThetaParams()),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "HVasUa4IbKuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating KatEnsembleParam with detailed configuration\n",
        "KatEnsembleParams = {\n",
        "    'models': model_params ,\n",
        "    'aggregation': 'median' ,\n",
        "    'seasonality_length': 7 ,\n",
        "    'decomposition_method': 'multiplicative'\n",
        "}"
      ],
      "metadata": {
        "id": "hW-3R0R8bQaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a Time Series dataset\n",
        "bitcoin_ts = TimeSeriesData(value = bitcoin_prices.Price,\n",
        "                            time = bitcoin_prices.index ,\n",
        "                            sort_by_time= True)\n",
        ""
      ],
      "metadata": {
        "id": "5DbdBlLVbR-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a KatEnsemble model (or) instantiating it\n",
        "ensemble_model = KatsEnsemble(\n",
        "    data = bitcoin_ts ,\n",
        "    params = KatEnsembleParams\n",
        ")\n",
        "\n",
        "# Fitting the model\n",
        "ensemble_model.fit()"
      ],
      "metadata": {
        "id": "L7mzSkVhbTjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Making prediction for the next 30 days\n",
        "forecast = ensemble_model.predict(steps = 30)"
      ],
      "metadata": {
        "id": "iAAAAYCUbVMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Aggregate individual model results (we will get the predictions for 30 Days)\n",
        "ensemble_model.aggregate()"
      ],
      "metadata": {
        "id": "7HL1tsVgbXQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plotting the model\n",
        "ensemble_model.plot()"
      ],
      "metadata": {
        "id": "_w1hn6ubbYVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6xQnhYbbuls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}